{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marathi Mini GPT\n",
    "This notebook will explore steps for creating Transformer model which mimic 'Sakharam Gatne'. \n",
    "\n",
    "P. L. Deshpande, affectionately known as Pu La Deshpande, was a remarkable Marathi author, playwright, and humorist who captivated readers and audiences alike with his witty writing and astute observations of diverse personalities in day-to-day activities.\n",
    "\n",
    "Sakharam Gatane is a memorable character from Deshpande's book \"Vyakti Ani Valli,\" which is a collection of character sketches. The character of Sakharam Gatane has become iconic, representing the essence of Deshpande's astute observations and his unique style of storytelling.\n",
    "\n",
    "Our approach involved curating a dataset of Sakharam's dialogues and creating similar sentences to build a dialogue dataset. Leveraging the code from the nano-gpt lecture by Andrej Karpathy, we successfully developed a model capable of generating monologues for Sakharam Gatne.\n",
    "\n",
    "Most of code and structure of Transformer model taken from following [colab](https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing). You can refer this interesting [Youtube_Video](https://www.youtube.com/watch?v=kCc8FmEb1nY) for more better understanding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we load some real and similar dialouge of Sakharam from 'sakharam_sentences.txt' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('sakharam_senteces.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total character in dataset : 2551103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  2551103\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see some sentences of Sakharam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "рд╣реЗ рд╡рд╛рдХреНрдп рдорд▓рд╛ рдЖрдкрд▓реЗ рдЬреАрд╡рди рд╡рд┐рд╖рдпрдХ рд╕реВрддреНрд░ рд╡рд╛рдЯрддреЗ.\n",
      "тАЬрд╕рдВрдзреАтАЭ рдЕрдкреЛрдЖрдк рдирд╛рд╣реА рдШрдбрдд, рддреНрдпрд╛ рдШрдбрд╡рд╛рд╡реНрдпрд╛ рд▓рд╛рдЧрддрд╛рдд.\n",
      "рдХреЛрдгрддреЗрд╣реА рдЙрджреНрджрд┐рд╖реНрдЯ рдореЗрд╣рдирддреА рд╢рд┐рд╡рд╛рдп рд╕рд╛рдзреНрдп рд╣реЛрдд рдирд╕рддреЗ .\n",
      "рдЬреАрд╡рдирд╛рдЪреНрдпрд╛ рд╕рдорд░рд╛рдд рд░рдХреНрддрдмрдВрдмрд╛рд│ рд╡реНрд╣рд╛рдпрдЪреЗ рдкреНрд░рд╕рдВрдЧ рдпрд╛рдпрдЪреЗрдЪ.\n",
      "рдореЛрддреНрдпрд╛рдВрдЪреНрдпрд╛ рд╣рд╛рд░рд╛рдкреЗрдХреНрд╖рд╛ рдШрд╛рдорд╛рдЪреНрдпрд╛ рдзрд╛рд░рд╛рдВрдиреА  рдордиреБрд╖реНрдп рд╢реЛрднреВрди рджрд┐рд╕рддреЛ,  рдореЛрддреНрдпрд╛рдЪреНрдпрд╛ рд╣рд╛рд░рд╛рдВрдиреА рдлрдХреНрдд рд╕реМрдВрджрд░реНрдп рджрд┐рд╕рддрдВ,  рдкрдг рдШрд╛рдорд╛рдЪреНрдпрд╛ рдзрд╛рд░рд╛рдВрдиреА рдХрд░реНрддреБрддреНрд╡ рд╕рд┐рджреНрдз рд╣реЛрдд..\n",
      "рдлрдХреНрдд рд╕реНрд╡рдд:рд╕рд╛рдареА рдЬрдЧрд▓рд╛рд╕ рддрд░ рдореЗрд▓рд╛рд╕  рдЖрдгрд┐ рд╕реНрд╡рдд:рд╕рд╛рдареА рдЬрдЧреВрди рджреБрд╕рд▒реНрдпрд╛рдВрд╕рд╛рдареА  рдЬрдЧрд▓рд╛рд╕ рддрд░ рдЬрдЧрд▓рд╛рд╕ ! рдкреНрд░рддреНрдпреЗрдХ рдпрд╢рд╕реНрд╡реА рдкреБрд░реБрд╖рд╛рдорд╛рдЧреЗ рдПрдХ рд╕реНрддреНрд░реА рдЕрд╕рддреЗ.\n",
      "рдкреНрд░рд╛рдЬреНрдЮ рдкрд░реАрдХреНрд╖реЗрдд рдкрд╛рд╕ рдЭрд╛рд▓реЛ.\n",
      "рджреБрд╕рд░реА: рдЬреЗ рдорд┐рд│рд╡рд▓реЗ рдЖрд╣реЗ рддреЗрдЪ рдЖрд╡рдбреВрди рдШреНрдпрд╛рдпрд▓рд╛ рд╢рд┐рдХрд╛ .\n",
      "рдкреНрд░рдпрддреНрди рдХрд░рдд рд░рд╛рд╣рд╛ рдХрд╛рд░рдг рд╕реБрд░реБрд╡рд╛рдд рдиреЗрд╣рдореА рдХрдареАрдгрдЪ рдЕрд╕рддреЗ .\n",
      "рдпрд╛ рдкреБрдвреЗ рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдореА рдХрд╕рд▓реАрдЪ рддрд╕рджреА рджреЗрдгрд╛рд░ рдирд╛рд╣реА.\n",
      "рдкреНрд░рд╕рд┐рдзреНрджреА рд╣реА рдЕрд╢реА рдмрд╛рдм рдЖрд╣реЗ рдЬреА рдХрд┐рддреАрд╣реА рдорд┐рд│рд╛рд▓реА рддрд░реА рдорд╛рдгрд╕рд╛рдЪреА рддрд╣рд╛рди рднрд╛рдЧрдд рдирд╛рд╣реА.\n",
      "рдЪреБрдХ рд╣реА рдЪреБрдХрдЪ рдЕрд╕рддреЗ, рдХреЛрдгреА рдХреЗрд▓реА рдпрд╛рд▓рд╛ рдорд╣рддреНрд╡ рдирд╕рддреЗ.\n",
      "рдЖрдгрд┐ рдЬреАрд╡рдирд╛рд╢реАрд╣реА.\n",
      "рдХрд╛рд│рдЬрд╛рдЪреА рдкреНрд░рддреНрдпреЗрдХ рдЬрдЦрдо рднрд░реВрди рдпреЗрддреЗ рдХрд╛рд░рдг рдХрд╛рд│ рджреБрдГрдЦрд╛рд╡рд░ рдорд╛рдпреЗрдЪреА рдлреБрдВрдХрд░ рдШрд╛рд▓рдд рдЕрд╕рддреЛ.\n",
      "рджреЗрд╡рд╛рдЪреЗ рдЖрднрд╛рд░.\n",
      "рдЖрдкрд▓реНрдпрд╛ рд╕рд╛рдзрдиреЗрдд рд╡реНрдпрддреНрдпрдп рддрд░ рдирд╛рд╣реАрдирд╛ рдЖрдгрд▓рд╛.\n",
      "рдЬреЗ рдЖрдордЪреНрдпрд╛ рд╣рд╛рддреВрди рдШрдбрд▓реЗ рдирд╛рд╣реА рддреЗ рддреБрдореНрд╣реА рдХрд░реВрди рджрд╛рдЦрд╡рд╛.\n",
      "рд╕рд░реНрд╡ рдЧреЛрд╖реНрдЯреАрдВрдирд╛ рдкреБрд░реВрди рдЙрд░рдгрд╛рд░реА рдПрдХрдЪ рдЧреЛрд╖реНрдЯ рдЖрд╣реЗ .\n",
      "рдорд╛рдЭреНрдпрд╛ рдпрд╛ рдореБрдЧреНрдз рд╡рд╛рдХреНрдпрд╛рд▓рд╛ рд╣рд╕рдгреЗ рд╕рд╛рд╣рдЬрд┐рдХ рдЖрд╣реЗ\n"
     ]
    }
   ],
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see vocabulary which contains Devnagari letters, some puctuations and smileys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !%(),-./015:;?|┬ардВрдГрдЕрдЖрдЗрдИрдЙрдКрдЛрдОрдПрдРрдУрдФрдХрдЦрдЧрдШрдЩрдЪрдЫрдЬрдЭрдЮрдЯрдардбрдврдгрддрдерджрдзрдирдкрдлрдмрднрдордпрд░рд▒рд▓рд│рд╡рд╢рд╖рд╕рд╣рд╝рд╛рд┐реАреБреВреГреДреЕреЗреИреЙреЛреМреНреЯредреережрезреирекрелремреорептАНтАУтАШтАЩтАЬтАЭтАжтШСя╕ПЁЯМ╕ЁЯМ┐ЁЯПЛЁЯП╗ЁЯТкЁЯТпЁЯУЪЁЯФКЁЯФ░ЁЯФ▒ЁЯШДЁЯШЗЁЯШКЁЯШОЁЯЩПЁЯдФЁЯдЯЁЯд╛\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are creating encoder and decoders. As this is character based model we are creating charector to integer and reverse maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65, 56, 58, 68, 47, 1, 58, 32, 81, 47, 54, 18, 54, 68, 61]\n",
      "рд╕рдорд░рд╛рдд рд░рдХреНрддрдмрдВрдмрд╛рд│\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "print(encode(\"рд╕рдорд░рд╛рдд рд░рдХреНрддрдмрдВрдмрд╛рд│\"))\n",
    "print(decode(encode(\"рд╕рдорд░рд╛рдд рд░рдХреНрддрдмрдВрдмрд╛рд│\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see sentence dataset in Integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2551103]) torch.int64\n",
      "tensor([66, 76,  1, 62, 68, 32, 81, 57,  1, 56, 60, 68,  1, 21, 52, 60, 76,  1,\n",
      "        39, 70, 62, 51,  1, 62, 69, 64, 57, 32,  1, 65, 72, 47, 81, 58,  1, 62,\n",
      "        68, 42, 47, 76,  8,  0, 97, 65, 18, 50, 70, 98,  1, 20, 52, 79, 21, 52,\n",
      "         1, 51, 68, 66, 70,  1, 35, 44, 47,  6,  1, 47, 81, 57, 68,  1, 35, 44,\n",
      "        62, 68, 62, 81, 57, 68,  1, 60, 68, 34, 47, 68, 47,  8,  0, 32, 79, 46,\n",
      "        47, 76, 66, 70,  1, 24, 49, 81, 49, 69, 64, 81, 42,  1, 56, 76, 66, 51,\n",
      "        47, 70,  1, 63, 69, 62, 68, 57,  1, 65, 68, 50, 81, 57,  1, 66, 79, 47,\n",
      "         1, 51, 65, 47, 76,  1,  8,  0, 39, 70, 62, 51, 68, 37, 81, 57, 68,  1,\n",
      "        65, 56, 58, 68, 47,  1, 58, 32, 81, 47, 54, 18, 54, 68, 61,  1, 62, 81,\n",
      "        66, 68, 57, 37, 76,  1, 52, 81, 58, 65, 18, 34,  1, 57, 68, 57, 37, 76,\n",
      "        37,  8,  0, 56, 79, 47, 81, 57, 68, 18, 37, 81, 57, 68,  1, 66, 68, 58,\n",
      "        68, 52, 76, 32, 81, 64, 68,  1, 35, 68, 56, 68, 37, 81, 57, 68,  1, 50,\n",
      "        68, 58, 68, 18, 51, 70,  1,  1, 56, 51, 71, 64, 81, 57,  1, 63, 79, 55,\n",
      "        72, 51,  1, 49, 69, 65, 47, 79,  6,  1,  1, 56, 79, 47, 81, 57, 68, 37,\n",
      "        81, 57, 68,  1, 66, 68, 58, 68, 18, 51, 70,  1, 53, 32, 81, 47,  1, 65,\n",
      "        80, 18, 49, 58, 81, 57,  1, 49, 69, 65, 47, 18,  6,  1,  1, 52, 46,  1,\n",
      "        35, 68, 56, 68, 37, 81, 57, 68,  1, 50, 68, 58, 68, 18, 51, 70,  1, 32,\n",
      "        58, 81, 47, 71, 47, 81, 62,  1, 65, 69, 49, 81, 50,  1, 66, 79, 47,  8,\n",
      "         8,  0, 53, 32, 81, 47,  1, 65, 81, 62, 47, 13, 65, 68, 43, 70,  1, 39,\n",
      "        34, 60, 68, 65,  1, 47, 58,  1, 56, 76, 60, 68, 65,  1,  1, 21, 46, 69,\n",
      "         1, 65, 81, 62, 47, 13, 65, 68, 43, 70,  1, 39, 34, 72, 51,  1, 49, 71,\n",
      "        65, 59, 81, 57, 68, 18, 65, 68, 43, 70,  1,  1, 39, 34, 60, 68, 65,  1,\n",
      "        47, 58,  1, 39, 34, 60, 68, 65,  1,  2,  1, 52, 81, 58, 47, 81, 57, 76,\n",
      "        32,  1, 57, 63, 65, 81, 62, 70,  1, 52, 71, 58, 71, 64, 68, 56, 68, 34,\n",
      "        76,  1, 28, 32,  1, 65, 81, 47, 81, 58, 70,  1, 20, 65, 47, 76,  8,  0,\n",
      "        52, 81, 58, 68, 39, 81, 41,  1, 52, 58, 70, 32, 81, 64, 76, 47,  1, 52,\n",
      "        68, 65,  1, 40, 68, 60, 79,  8,  0, 49, 71, 65, 58, 70, 13,  1, 39, 76,\n",
      "         1, 56, 69, 61, 62, 60, 76,  1, 21, 66, 76,  1, 47, 76, 37,  1, 21, 62,\n",
      "        44, 72, 51,  1, 35, 81, 57, 68, 57, 60, 68,  1, 63, 69, 32, 68,  1,  8,\n",
      "         0, 52, 81, 58, 57, 47, 81, 51,  1, 32, 58, 47,  1, 58, 68, 66, 68,  1,\n",
      "        32, 68, 58, 46,  1, 65, 71, 58, 71, 62, 68, 47,  1, 51, 76, 66, 56, 70,\n",
      "         1, 32, 43, 70, 46, 37,  1, 20, 65, 47, 76,  1,  8,  0, 57, 68,  1, 52,\n",
      "        71, 45, 76,  1, 21, 52, 60, 81, 57, 68, 60, 68,  1, 56, 70,  1, 32, 65,\n",
      "        60, 70, 37,  1, 47, 65, 49, 70,  1, 49, 76, 46, 68, 58,  1, 51, 68, 66,\n",
      "        70,  8,  0, 52, 81, 58, 65, 69, 50, 81, 49, 70,  1, 66, 70,  1, 20, 63,\n",
      "        70,  1, 54, 68, 54,  1, 21, 66, 76,  1, 39, 70,  1, 32, 69, 47, 70, 66,\n",
      "        70,  1, 56, 69, 61, 68, 60, 70,  1, 47, 58, 70,  1, 56, 68, 46, 65, 68,\n",
      "        37, 70,  1, 47, 66, 68, 51,  1, 55, 68, 34, 47,  1, 51, 68, 66, 70,  8,\n",
      "         0, 37, 71, 32,  1, 66, 70,  1, 37, 71, 32, 37,  1, 20, 65, 47, 76,  6,\n",
      "         1, 32, 79, 46, 70,  1, 32, 76, 60, 70,  1, 57, 68, 60, 68,  1, 56, 66,\n",
      "        47, 81, 62,  1, 51, 65, 47, 76,  8,  0, 21, 46, 69,  1, 39, 70, 62, 51,\n",
      "        68, 63, 70, 66, 70,  8,  0, 32, 68, 61, 39, 68, 37, 70,  1, 52, 81, 58,\n",
      "        47, 81, 57, 76, 32,  1, 39, 33, 56,  1, 55, 58, 72, 51,  1, 57, 76, 47,\n",
      "        76,  1, 32, 68, 58, 46,  1, 32, 68, 61,  1, 49, 71, 19, 33, 68, 62, 58,\n",
      "         1, 56, 68, 57, 76, 37, 70,  1, 53, 71, 18, 32, 58,  1, 35, 68, 60, 47,\n",
      "         1, 20, 65, 47, 79,  8,  0, 49, 76, 62, 68, 37, 76,  1, 21, 55, 68, 58,\n",
      "         8,  0, 21, 52, 60, 81, 57, 68,  1, 65, 68, 50, 51, 76, 47,  1, 62, 81,\n",
      "        57, 47, 81, 57, 57,  1, 47, 58,  1, 51, 68, 66, 70, 51, 68,  1, 21, 46,\n",
      "        60, 68,  8,  0, 39, 76,  1, 21, 56, 37, 81, 57, 68,  1, 66, 68, 47, 72,\n",
      "        51,  1, 35, 44, 60, 76,  1, 51, 68, 66, 70,  1, 47, 76,  1, 47, 71, 56,\n",
      "        81, 66, 70,  1, 32, 58, 72, 51,  1, 49, 68, 33, 62, 68,  8,  0, 65, 58,\n",
      "        81, 62,  1, 34, 79, 64, 81, 42, 70, 18, 51, 68,  1, 52, 71, 58, 72, 51,\n",
      "         1, 24, 58, 46, 68, 58, 70,  1, 28, 32, 37,  1, 34, 79, 64, 81, 42,  1,\n",
      "        21, 66, 76,  1,  8,  0, 56, 68, 40, 81, 57, 68,  1, 57, 68,  1, 56, 71,\n",
      "        34, 81, 50,  1, 62, 68, 32, 81, 57, 68, 60, 68,  1, 66, 65, 46, 76,  1,\n",
      "        65, 68, 66, 39, 69, 32,  1, 21, 66, 76])\n"
     ]
    }
   ],
   "source": [
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide whole dataset into train and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define block size of 8 which means first 8 consecutive charecters predict next charecter in sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66, 76,  1, 62, 68, 32, 81, 57,  1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([66]) the target: 76\n",
      "when input is tensor([66, 76]) the target: 1\n",
      "when input is tensor([66, 76,  1]) the target: 62\n",
      "when input is tensor([66, 76,  1, 62]) the target: 68\n",
      "when input is tensor([66, 76,  1, 62, 68]) the target: 32\n",
      "when input is tensor([66, 76,  1, 62, 68, 32]) the target: 81\n",
      "when input is tensor([66, 76,  1, 62, 68, 32, 81]) the target: 57\n",
      "when input is tensor([66, 76,  1, 62, 68, 32, 81, 57]) the target: 1\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define random seed for consistent random values. We can see batch wise input in following node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[81, 57, 68, 47,  1, 32, 68, 57],\n",
      "        [55, 68,  1, 65, 68, 50, 51, 76],\n",
      "        [68, 58,  1, 63, 54, 81, 49,  1],\n",
      "        [50, 68, 51,  8,  0, 32, 60, 76]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[57, 68, 47,  1, 32, 68, 57,  1],\n",
      "        [68,  1, 65, 68, 50, 51, 76, 37],\n",
      "        [58,  1, 63, 54, 81, 49,  1, 65],\n",
      "        [68, 51,  8,  0, 32, 60, 76, 63]])\n",
      "----\n",
      "when input is [81] the target: 57\n",
      "when input is [81, 57] the target: 68\n",
      "when input is [81, 57, 68] the target: 47\n",
      "when input is [81, 57, 68, 47] the target: 1\n",
      "when input is [81, 57, 68, 47, 1] the target: 32\n",
      "when input is [81, 57, 68, 47, 1, 32] the target: 68\n",
      "when input is [81, 57, 68, 47, 1, 32, 68] the target: 57\n",
      "when input is [81, 57, 68, 47, 1, 32, 68, 57] the target: 1\n",
      "when input is [55] the target: 68\n",
      "when input is [55, 68] the target: 1\n",
      "when input is [55, 68, 1] the target: 65\n",
      "when input is [55, 68, 1, 65] the target: 68\n",
      "when input is [55, 68, 1, 65, 68] the target: 50\n",
      "when input is [55, 68, 1, 65, 68, 50] the target: 51\n",
      "when input is [55, 68, 1, 65, 68, 50, 51] the target: 76\n",
      "when input is [55, 68, 1, 65, 68, 50, 51, 76] the target: 37\n",
      "when input is [68] the target: 58\n",
      "when input is [68, 58] the target: 1\n",
      "when input is [68, 58, 1] the target: 63\n",
      "when input is [68, 58, 1, 63] the target: 54\n",
      "when input is [68, 58, 1, 63, 54] the target: 81\n",
      "when input is [68, 58, 1, 63, 54, 81] the target: 49\n",
      "when input is [68, 58, 1, 63, 54, 81, 49] the target: 1\n",
      "when input is [68, 58, 1, 63, 54, 81, 49, 1] the target: 65\n",
      "when input is [50] the target: 68\n",
      "when input is [50, 68] the target: 51\n",
      "when input is [50, 68, 51] the target: 8\n",
      "when input is [50, 68, 51, 8] the target: 0\n",
      "when input is [50, 68, 51, 8, 0] the target: 32\n",
      "when input is [50, 68, 51, 8, 0, 32] the target: 60\n",
      "when input is [50, 68, 51, 8, 0, 32, 60] the target: 76\n",
      "when input is [50, 68, 51, 8, 0, 32, 60, 76] the target: 63\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[81, 57, 68, 47,  1, 32, 68, 57],\n",
      "        [55, 68,  1, 65, 68, 50, 51, 76],\n",
      "        [68, 58,  1, 63, 54, 81, 49,  1],\n",
      "        [50, 68, 51,  8,  0, 32, 60, 76]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Bigram language model for sentence generation. In previous notebooks we developed this model, here we also use attention mechanism with Transformers.\n",
    "In this model we are using embedding layer which provide logits in following dimensions (B,T,C)\n",
    "Where B is Batch, T is time (charecter position) and C is channel or dimension for embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is no processing, we can see Sakharam speaking some gibberish ЁЯШДтАН"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 120])\n",
      "tensor(5.1255, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "|ЁЯШКреЗрд╝тАУтАНрдгреДрдЗтАНтАШрдЛтАНтАжрдЙрдард╣тШСрдЪрд╖.рдЪрдбрдЖрдардГрдЫрдордЭрдГремрезрем(рдИрдРрдЛреБрдО/реГ%рднЁЯФКреВрдЪЁЯТкрдВ:!рдЗ(рд╖реЗ!рдЪрдЩрдардЮЁЯПЛтАжрдФЁЯШДтАНтАЬрдЪрдЩ0рдИЁЯШДЁЯФ░ЁЯМ╕-рдЫЁЯФ░реиреВ.ЁЯУЪрекрдУ0рд╣реБрдПрд┐рдЛреерд│рдз:┬ареЕрдЩрд▒рдР5ЁЯМ╕ЁЯдЯтАУ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of SGD optimizer we will use more advanced Adam Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting initial loss value. : 5.109947681427002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.109947681427002\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100): # increase number of steps for good results... \n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 100 iterations we get following input, which is again gibberish one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|тАжрдгрд╝,ремрдЩрелЁЯПЛрдЫЁЯШОЁЯМ┐ЁЯМ┐рдереп рд╢реИрдЯреГЁЯМ┐рдРрдЦрдЬрдРрекрдГ| рдардО(ЁЯМ┐ЁЯд╛рд╕тАНрдЩЁЯдФрем5ЁЯШОрдЯреИЁЯПЛ:ЁЯШКтШСрд▓рдШЁЯФ░ЁЯП╗рд│рд╡рдИ-рдЛреНрелрдореАЁЯШОрд╣ЁЯЩПрдЦреердЦрдЭя╕ПрдГреИреж5рдЮрд░реоЁЯд╛реН)ЁЯТпрдлрео1-ЁЯдЯЁЯМ┐реЙ;рдКрддЁЯШО|рджрдирдгрдОрднрдЖрдЛрдИреНрд╡рдердврдЗрдг1реЛрдФрдЮрдЪ%реИрдЮ┬а/рднрежрдЗреДреирдЗреИтАжЁЯШЗтШС .ЁЯШД рдЕрд┐рдардЮ!ЁЯШОредреирд╢рем%:рдЦ)рдИрдирдЩрдЮрд░рдЮрдЛреетАЬ,)режЁЯШКремЁЯУЪрдмя╕П0редрдЖрдЬЁЯМ╕рд│ЁЯШК:ЁЯд╛рд│ЁЯЩПрдЪрд┐рдЛ,реи,тАЬрдЪремрд╛тАШЁЯФКрдлреМрдпрдврд╖релрдЭЁЯМ╕рджрдврдзтАНрд▓тАж реЯЁЯШДрдв?рдВтАЭрдЧтАжтАШ!редрд╖рдЪрежрдЛреДредреЙ:рдврдФЁЯФ░рдГрдмрд▒|рдЛрдв,рдгрд▒ЁЯМ╕ЁЯдЯреореЯрелрдПтАНрд╡рд╖ЁЯМ┐рдШрд╡рд┐ ЁЯПЛЁЯТптАУреГрдЖтШСрдЖтШСрд▓реЗрд╝тАУЁЯТкрдЦЁЯФКрд╢|?-рддрдп ЁЯТпрд▓тАжрдЕреерд│ЁЯТкрдГрдаЁЯПЛрдЗЁЯдЯрдгрдШрдРрдЦреирд╖тАЬрдХЁЯЩПреГ%рд│)ЁЯФ░рдГрезЁЯдЯрдЪрдВрдлрдРрдгреДЁЯМ╕ЁЯУЪрда?рдиреоремтАЭрдиредрдРреЗ)ЁЯУЪ%рдо(рдЩЁЯФКрдЦЁЯТпЁЯдЯЁЯУЪрдЭреНрдЬрд╖рд╣ЁЯУЪЁЯд╛реЕрд┐реердФреМтАУЁЯШДрдО/реЯ5рекреетАШрдЪ!ЁЯФ░рдГреИрд╛ЁЯФКтАШЁЯМ┐1рдЯрд╢ЁЯШОреМрдарел(рд╕рдЙреЛ!реГЁЯМ┐тАжрдкреМрд╝тАШрд╣реДЁЯШОрд╛ЁЯПЛЁЯШКрдбрд╕рдЯрдЖ%!рдГрдУрдЛрдЙрдЪЁЯдФя╕Препрд╡\n",
      "рдмЁЯУЪ-тАЩЁЯМ┐рдлрекрепрдУЁЯУЪрезремреАрдХрдЗрдИрд╝рдВрдЭЁЯШДрежрджтАЩЁЯМ┐реДрдИ0рдЕЁЯПЛрд▒реДтАШрдктАжрде?ЁЯдФтАНрдЙЁЯЩПрдкрдЗтАШЁЯд╛рд▓тАНрд╕0рдЧрдЩреБЁЯТпрдлрдмЁЯФ▒|рдУ%рдРрд╢ЁЯдЯреАЁЯФ▒рдИЁЯШОЁЯЩП1тШСрд┐рдзЁЯд╛рдЕЁЯМ╕ЁЯФ▒ЁЯШЗЁЯШЗ-!рдвремрдЩрдРрдУ;5тАШрде%(тАНтАУреЯрдГЁЯМ╕рдЦреиреМреАЁЯдФ,ЁЯдФрд┐рдУрдкрдШрдЮ\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following some nodes demonstrate way to calculate weighted aggregation. We are using last example in our Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all calculation regarding self attention is describe with following terms,\n",
    "Key (key) : It explain what data want to show to other participating data during define meaning in Transformer network training.\n",
    "Query (query) : It explain what data expecting from other participator\n",
    "Value (value) : What data actually have or think about self.\n",
    "\n",
    "Whatever magical results we get from Transformer model are happen because of communication between data particles which used Key, Query and Value as token of communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code explains Layer Normalization which enhance quality of results in very Deep Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.5763e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is final code for Transformer network we are using to emulate Sakharam Gatne.\n",
    "As compare with original colab we change some hyperparameters like\n",
    "\n",
    "Batch Size : 64\n",
    "\n",
    "Block Size : 64\n",
    "\n",
    "n_embd : 256 (charecter embedding dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.234424 M parameters\n",
      "step 0: train loss 5.0258, val loss 5.0258\n",
      "step 100: train loss 2.4135, val loss 2.4146\n",
      "step 200: train loss 1.9184, val loss 1.9219\n",
      "step 300: train loss 1.5883, val loss 1.5911\n",
      "step 400: train loss 1.3475, val loss 1.3626\n",
      "step 500: train loss 1.1880, val loss 1.2051\n",
      "step 600: train loss 1.0699, val loss 1.0857\n",
      "step 700: train loss 0.9562, val loss 0.9856\n",
      "step 800: train loss 0.8756, val loss 0.8973\n",
      "step 900: train loss 0.8001, val loss 0.8265\n",
      "step 1000: train loss 0.7380, val loss 0.7636\n",
      "step 1100: train loss 0.6760, val loss 0.7061\n",
      "step 1200: train loss 0.6453, val loss 0.6662\n",
      "step 1300: train loss 0.6039, val loss 0.6291\n",
      "step 1400: train loss 0.5616, val loss 0.5930\n",
      "step 1500: train loss 0.5355, val loss 0.5729\n",
      "step 1600: train loss 0.5144, val loss 0.5426\n",
      "step 1700: train loss 0.4921, val loss 0.5238\n",
      "step 1800: train loss 0.4797, val loss 0.5048\n",
      "step 1900: train loss 0.4594, val loss 0.4784\n",
      "step 2000: train loss 0.4501, val loss 0.4757\n",
      "step 2100: train loss 0.4323, val loss 0.4528\n",
      "step 2200: train loss 0.4185, val loss 0.4459\n",
      "step 2300: train loss 0.4093, val loss 0.4353\n",
      "step 2400: train loss 0.3987, val loss 0.4301\n",
      "step 2500: train loss 0.3922, val loss 0.4131\n",
      "step 2600: train loss 0.3905, val loss 0.4145\n",
      "step 2700: train loss 0.3816, val loss 0.4043\n",
      "step 2800: train loss 0.3732, val loss 0.3961\n",
      "step 2900: train loss 0.3722, val loss 0.3942\n",
      "step 3000: train loss 0.3647, val loss 0.3847\n",
      "step 3100: train loss 0.3611, val loss 0.3821\n",
      "step 3200: train loss 0.3576, val loss 0.3763\n",
      "step 3300: train loss 0.3593, val loss 0.3784\n",
      "step 3400: train loss 0.3512, val loss 0.3692\n",
      "step 3500: train loss 0.3489, val loss 0.3641\n",
      "step 3600: train loss 0.3461, val loss 0.3666\n",
      "step 3700: train loss 0.3430, val loss 0.3590\n",
      "step 3800: train loss 0.3383, val loss 0.3589\n",
      "step 3900: train loss 0.3394, val loss 0.3578\n",
      "step 4000: train loss 0.3367, val loss 0.3517\n",
      "step 4100: train loss 0.3349, val loss 0.3499\n",
      "step 4200: train loss 0.3327, val loss 0.3489\n",
      "step 4300: train loss 0.3291, val loss 0.3443\n",
      "step 4400: train loss 0.3277, val loss 0.3458\n",
      "step 4500: train loss 0.3280, val loss 0.3453\n",
      "step 4600: train loss 0.3225, val loss 0.3405\n",
      "step 4700: train loss 0.3278, val loss 0.3394\n",
      "step 4800: train loss 0.3248, val loss 0.3380\n",
      "step 4900: train loss 0.3221, val loss 0.3352\n",
      "step 5000: train loss 0.3239, val loss 0.3390\n",
      "step 5100: train loss 0.3232, val loss 0.3381\n",
      "step 5200: train loss 0.3181, val loss 0.3313\n",
      "step 5300: train loss 0.3168, val loss 0.3329\n",
      "step 5400: train loss 0.3189, val loss 0.3323\n",
      "step 5500: train loss 0.3165, val loss 0.3268\n",
      "step 5600: train loss 0.3149, val loss 0.3256\n",
      "step 5700: train loss 0.3140, val loss 0.3273\n",
      "step 5800: train loss 0.3133, val loss 0.3260\n",
      "step 5900: train loss 0.3126, val loss 0.3259\n",
      "step 6000: train loss 0.3132, val loss 0.3246\n",
      "step 6100: train loss 0.3124, val loss 0.3253\n",
      "step 6200: train loss 0.3103, val loss 0.3200\n",
      "step 6300: train loss 0.3099, val loss 0.3237\n",
      "step 6400: train loss 0.3095, val loss 0.3206\n",
      "step 6500: train loss 0.3088, val loss 0.3199\n",
      "step 6600: train loss 0.3077, val loss 0.3190\n",
      "step 6700: train loss 0.3050, val loss 0.3207\n",
      "step 6800: train loss 0.3045, val loss 0.3185\n",
      "step 6900: train loss 0.3048, val loss 0.3158\n",
      "step 7000: train loss 0.3013, val loss 0.3125\n",
      "step 7100: train loss 0.3025, val loss 0.3117\n",
      "step 7200: train loss 0.3029, val loss 0.3127\n",
      "step 7300: train loss 0.3005, val loss 0.3142\n",
      "step 7400: train loss 0.3013, val loss 0.3120\n",
      "step 7500: train loss 0.2994, val loss 0.3104\n",
      "step 7600: train loss 0.3013, val loss 0.3124\n",
      "step 7700: train loss 0.2990, val loss 0.3099\n",
      "step 7800: train loss 0.2970, val loss 0.3077\n",
      "step 7900: train loss 0.2977, val loss 0.3075\n",
      "step 8000: train loss 0.2980, val loss 0.3099\n",
      "step 8100: train loss 0.2973, val loss 0.3078\n",
      "step 8200: train loss 0.2962, val loss 0.3081\n",
      "step 8300: train loss 0.2988, val loss 0.3098\n",
      "step 8400: train loss 0.2931, val loss 0.3048\n",
      "step 8500: train loss 0.2963, val loss 0.3061\n",
      "step 8600: train loss 0.2934, val loss 0.3068\n",
      "step 8700: train loss 0.2965, val loss 0.3061\n",
      "step 8800: train loss 0.2955, val loss 0.3058\n",
      "step 8900: train loss 0.2927, val loss 0.3040\n",
      "step 9000: train loss 0.2917, val loss 0.3015\n",
      "step 9100: train loss 0.2914, val loss 0.3009\n",
      "step 9200: train loss 0.2931, val loss 0.3049\n",
      "step 9300: train loss 0.2899, val loss 0.3047\n",
      "step 9400: train loss 0.2928, val loss 0.3028\n",
      "step 9500: train loss 0.2927, val loss 0.3043\n",
      "step 9600: train loss 0.2912, val loss 0.3015\n",
      "step 9700: train loss 0.2887, val loss 0.3007\n",
      "step 9800: train loss 0.2916, val loss 0.2995\n",
      "step 9900: train loss 0.2901, val loss 0.2983\n",
      "step 9999: train loss 0.2886, val loss 0.2975\n",
      "\n",
      "рдХреЗрд▓реНрдпрд╛рдиреЗ рд╣реЛрдд рдЖрд╣реЗ рд░реЗ рдЖрдзреА рдХреЗрд▓реЗрдЪреА рдкрд╛рд╣реАрдЬрд░ рддреБрдореНрд╣реА рдиреЗрд╣рдореАрдЪ рд╕рд╛рд░реНрд╡рд╕рд╛рдзрд╛рд░рдг рдЬреАрд╡рди рдЬрдЧрдгреНрдпрд╛рдЪрд╛ рдкреНрд░рдпрддреНрди рдХрд░реАрдд рдЕрд╕рд╛рд▓рдВ рддрд░, рддреБрдореНрд╣рд╛рд▓рд╛ рдХрдзреАрдЪ рд╣реЗ рдЙрдордЬрдгреНрдпрд╛рдЪрд╛ рдорд╛рдгрд╕ рдирдХреНрдХреА рд╣реЛрдд рдЖрд╣реЗ.\n",
      "рдкреНрд░рддреНрдпреЗрдХ рдХреНрд╖рдгреА рд╣рд╛ рдЕрдореВрд▓реНрдп рдЖрд╣реЗ, рддреЛ рдЖрдирдВрджрд╛рдиреЗ рдЬрдЧрд╛ рдЖрдгрд┐ рдкреНрд░рддреНрдпреЗрдХ рд╣реГрджрдп рдЬрд┐рдВрдХрдд рд░рд╣рд╛.\n",
      "рд╕реНрд╡рддрдГрд╡рд░ рд╡рд┐рд╢реНрд╡рд╛рд╕ рдЕрд╕рд▓рд╛ рдХреА, рдЬрд┐рд╡рдирд╛рдЪреА рд╕реБрджреНрдзрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдВрд╡рд░ рдЕрд╡рд▓рдВрдмреВрди рдЕрд╕рддреЗ .\n",
      "рдЖрдкрд▓реНрдпрд╛ рдкрд╣рд┐рд▓реНрдпрд╛ рднреЗрдЯреАрддреАрд▓ рджрд┐рд▓реЗрд▓реА рд╕реНрд╡рд╛рдХреНрд╖рд░реА рдореА рдЖрдЬрд╣реА рд╡рд╛рдЪрддреЛ.\n",
      "рддреЛ рдЪреБрдХреАрдЪреЗ рдХрд╛рдо рдХрд░рдд рдирд╕рд▓реНрдпрд╛рдиреЗ рддреНрдпрд╛рд▓рд╛ рдЪрд┐рдВрддрд╛ рдирд╕рддреЗ, рддреНрдпрд╛рдЪреНрдпрд╛рдХрдбреЗ рдард╛рдо рд╡рд┐рдЪрд╛рд░ рдЕрд╕рд▓реНрдпрд╛рдиреЗ рддреЗ рдЦреБрдк рдирд╛рддреА рдбреЛрд│реНрдпрд╛рдВрддреА рдЖрд╣реЗ.\n",
      "рдорд╛рддреГрддреНрд╡рд╛рд╡рд░ рдЕрд╡рд▓рдВрдмреВрди рдЕрд╕рддреЗ.\n",
      "рдПрдЦрд╛рджреНрдпрд╛рд▓рд╛ рдЧреБрдиреНрд╣реЗрдЧрд╛рд░ рдард░рд╡рд┐рддрд╛ рддреНрдпрд╛рдЪреНрдпрд╛ рдЬрд╛рдЧреА рд╕реНрд╡рдд рд▓рд╛ рдЕрдЯреНрдЯ рд╕рдореНрд░рд╛рдЯрд╛рдкреЗрдХреНрд╖рд╛ рдХрд┐рддреАрддрд░реА рд╢реНрд░реЗрд╖реНрда рдЕрд╕рддреЛ.\n",
      "рд╡рд╛рд╣рддреЛ рддреЛ рдЭрд░рд╛ рдЖрдгрд┐ рдерд╛рдВрдмрддреЗ рддреЗ рдбрдмрдХрдВ .\n",
      "рд╕рд╛рд╣рд┐рддреНрдпрд╛рд╢реА рдПрдХрдирд┐рд╖реНрда рд░рд╛рд╣рд╛.\n",
      "рдЖрдпреБрд╖реНрдпрд╛рддреАрд▓ рдЕрд╕рдВрдЦреНрдп рд╕рдорд╕реНрдпрд╛рдВрд╕рдореЛрд░ рдХрдзреА рдХрдзреА рдирд╢реАрдм рд╣рд╛рддрд╛рдд рдпреЗрдд рдирд╛рд╣реА  рддреЛ рдкрд░реНрдпрдВрдд рдирд╢рд┐рдмрд╛рдиреЗ  рдЖрд▓реЗрд▓реЗ рд╣рд╛рдд рд╡рд╛рдкрд░рд╛.ЁЯТкЁЯП╗ЁЯТкЁЯП╗  рдЪрд╛рдВрдЧрд▓реА рд╡реЗрд│ рдмрдШрд╛рдпрдЪреА  рдЕрд╕реЗрд▓ рддрд░ рддреА рд╡рдХреНрддрдмрдВрдмрд╛рд│ рд╡реНрд╣рд╛рдпрдЪреЗ рдкреНрд░рд╕рдВрдЧ рдпрд╛рдпрдЪреЗрдЪ.\n",
      "рдПрдХрджрд╛ рдХрд░реНрддреГрддреНрд╡ рд╕рд┐рджреНрдз рдЭрд╛рд▓рдВ рдХрд┐, рд╕рдВрд╢рдпрд╛рдиреЗ рдмрдШрдгрд╛рд▒реНрдпрд╛ рдирдЬрд░рд╛ рдЖрдкреЛрдЖрдк рдЖрджрд░рд╛рдирдВ рдЭреБрдХрддрд╛рдд рдЪрд┐рдВрддрд╛ рдЖрдгрд┐ рддрдгрд╛рд╡ рдареЗрд╡рдгреЗ рд╣реЗ рд╡рд╛рдЩрд╛рдЪреЗ рдорд╣рддреНрддреНрд╡ рдЖрдгрд┐ рдкреБрд░реВрди рдЙрд░рдгрд╛рд░реА рд╕рдВрдкрддреНрддреА рддреНрдпрд╛рдВрдирд╛ рддреБрдореНрд╣реА рдмрд╛рд│рдЧрд▓реЗрд▓рд╛ рд╕рдВрдпрдо рдЖрдгрд┐ рддреБрдордЪреНрдпрд╛рдЬрд╡рд│ рд╕рддрд╛рдд рдХрд╛рдо рд╣реЗ рдХрдзреА рдЖрд╣реЗ рддреНрдпрд╛рд▓рд╛ рд╕реНрд╡рддрдГрдЪреЗ рдЕрд╕реНрддрд┐рддреНрд╡ рд╢реВрдиреНрдп рдЕрд╕рддреЗ.\n",
      "рдЖрдкрд▓реНрдпрд╛ рд╕рд╛рдзрдиреЗрдд рд╡реНрдпрддреНрдпрдп рддрд░ рдирд╛рд╣реАрдирд╛ рдЖрдгрд▓рд╛.\n",
      "рдЧрд░реНрджреАрдЪрд╛ рд╣рд┐рд╕реНрд╕рд╛ рдирд╛рд╣реА, рдЧрд░реНрджреАрдЪ рдХрд╛рд░рдг рдмрдирд╛рдпрдЪрдВ .\n",
      "рдЙрджреНрдпрд╛рд╕рд╛рдареАрдЪреА рд╕рдВрдзреА рджреЗрдИрд▓ рддреНрдпрд╛ рдкрд░рд╛рдЦреЗрддреВрди рдирд┐рд░реНрдорд╛рдг рд╣реЛрдгреНрдпрд╛рдЪреА .\n",
      "рд╕рд░реНрд╡рдЪ рдкреНрд░рд╢реНрди рд╕реЛрдбрд╡реВрди рд╕реВрдЯрдд рдирд╛рд╣реАрдд; рдХрд╛рд╣реА рд╕реЛрдбреВрди рджрд┐рд▓реЗ рдХреА рдЖрдкреЛрдЖрдк рд╕реБрдЯрддрд╛рдд.\n",
      "рдорд▓рд╛ рдХреНрд╖рдорд╛ рдХрд░рд╛.\n",
      "рд╕реНрд╡рдкреНрди рдкрд╛рд╣рддрдЪ рдЕрд╕рд╛рд▓рдВ рддрд░ рдореЛрдареАрдЪ рдкрд╛рд╣рд╛.\n",
      "рддреНрдпрд╛рдВрдирд╛ рд╣реЗ рдорд╛рд╣реАрддрд░ рдиреЗрд╣рдореАрдЪ рдЕрдкреВрд░реНрдг рдЕрд╕рддреЗ.\n",
      "рдЬрдЧ рдПрдЦрд╛рджреНрдпрд╛рд▓рд╛ реи рдкрдзреНрджрд░ рдХреЛрдгреА рд╕рдВрдкреЗрдХреНрд╖рд╛ рдЯрд┐рдХреВрди рд░рд╛рд╣реЗрдВрдЪрд╛ рдЕрдВрддрдГрд╛рд░ рд╣реЛрдд рддреЗ рдХрд░рдгреЗ рдХрд┐рдВрд╡рд╛ рдЙрдШрдбреНрдпрд╛ рдбреЛрд│реНрдпрд╛рдВрдиреА рдкрд╛рд╣рдгреЗ рд╣реЗ рдорд╣рд╛рдкрд╛рдк .\n",
      "рдХреАрд░реНрддреА рд╣реЛрдК рджреБрд░реНрдмрд▓ рд░рд╛рд╣реВ рдирдХрд╛ .\n",
      "рдЬреАрд╡рдиреЛрдиреНрдирддреАрдЪреЗ рд╕рд╣рд╛ рд╕реЛрдкрд╛рди.\n",
      "рдЗрдЪреНрдЫрд╛ рджрд╛рдВрдбрдЧреА рдЕрд╕рд▓реА рдХреА рдорджрдж рдЖрдкрдгрд╣реВрди рддреБрдордЪреНрдпрд╛рдХрдбреЗ рдЪрд╛рд▓рдд рдпреЗрддреЗ.\n",
      "тАЬрддреБрдордЪреНрдпрд╛ рд╕реНрд╡рдкреНрдирд╛рдВрдирд╛ рдХрдзреА рдХрдзреА рдЪреБрдХреАрдЪреА рдЪреБрдХреАрдЪреА рдЪрд╡ рдХрд╛рд╣реА рдирд╡реА рд╕реЗрдЪ рдХреАрд░реНрддреА рд▓рд╛рднрддреЗ.\n",
      "рдкреНрд░рд╛рдкреНрддреАрдкреЗрдХреНрд╖рд╛ рдкреНрд░рдпрддреНрдирд╛рдВрдЪрд╛ рдЖрдирдВрдж рдЕрдзрд┐рдХ рдЕрд╕рддреЛ .\n",
      "рдкрд╛рддреНрд░рддрд╛ рдирд╛рд╣реА рдореНрд╣рдгреВрди рджреБрд░реНрдмрд▓ рд░рд╛рд╣реВ рдирдХрд╛ .\n",
      "рдХреЗрддрдХреА рдкрд┐рд╡рд│реА рдкрдбрд▓реА.\n",
      "рджреБрд░реНрдЧреБрдгрд╛рдВрдЪрд╛ рдордВрддреНрд░ рдореНрд╣рдгрдЬреЗ рджреБ:рдЦ рдХрд╛рд░рдг рдкрд╛рдбрдд рдирд╛рд╣реА.\n",
      "рдорд┐рддреНрд░рд╛рдЪреНрдпрд╛ рдореГрддреНрдпреВрдкреЗрдХреНрд╖рд╛ рдореИрддреНрд░реАрдЪрд╛ рдореГрддреНрдпреВ рдЕрдзрд┐рдХ рджреБрдГрдЦрджрд╛рдпрдХ рдЕрд╕рддреЛ.\n",
      "рдорд╛рдЭреНрдпрд╛ рдЬреАрд╡рдирд╛рдд рдПрдХ рдирд╡реЗ рдкрд░реНрд╡ рд╕реБрд░реБ рд╣реЛрдд рдЖрд╣реЗ.\n",
      "рдЬреАрд╡рдирд╛рддреАрд▓ рдкреНрд░рддреНрдпреЗрдХ рдШрдЯрдиреЗрд▓рд╛ рдЕрд░реНрде рдЕрд╕рддреЛ.\n",
      "рдпрд╢ рд╣реЗ рд╕реЛрдкреЗ рдХрд╛рд░рдг рддреЗ рдХрд╢рд╛рдЪреНрдпрд╛ рддрд░реА рддреБрд▓рдиреЗрдд рдЕрд╕рддреЗ, рдкрдг рд╕рдорд╛рдзрд╛рди рд╣реЗ рдорд╣рддреНрд╡рд╛рдЪрд╛ рдирд╕реВрди рддреНрдпрд╛ рдХрд┐рдгрд╛-рдпрд╛рд▓рд╛ рдХрд┐рддреА рд╕реНрдкрд░реНрд╢ рдХрд░рддрд╛рдд.\n",
      "рдЕрд╕рд╛ рд╡реНрдпрд╛рд╕рдВрдЧ рдХрд░рд╛рдпрдЪреА рдЗ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 64 # what is the maximum context length for predictions?\n",
    "max_iters = 10000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 256\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('sakharam_senteces.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "рд╣рд╛рдгрд╛рд░рд╛ рд╣рд╛рдЪ рдкреНрд░реАрддреАрдЪрд╛ рдкреНрд░рд╛рдг рд╣реЛрдп.\n",
      "рдЕрдЗрддрдХреЗ рдЙрдкрд╛рдп рдмреЛрд▓реВрди рд╢рд┐рдХрд╛ рдирд╛рд╣реА рдкрдг рдЬрдд рдЕрд╕реЗ рдирд╛рд╣реА.\n",
      "рдкреНрд░рдпрд╛рд╕ рд╣рд╛ рдкреНрд░рддрд┐рднреЗрдЪрд╛ рдкреНрд░рд╛рдгрд╡рд╛рдпреВ рдЖрд╣реЗ.\n",
      "рдкреНрд░рддреНрдпреЗрдХрд╛рдиреЗ рдард░рд╡рд╛рдпрдЪреЗ рдХреА рдЖрдкрдг рдХреЛрдг рдЖрд╣реЛрдд рдпрд╛рд╡рд░ рд╕реБрдЦ рдХрдзреАрдЪ рдЕрд╡рд▓рдВрдмреВрди рдирд╕рдд.\n",
      "рдЬрд░ рддреБрдореНрд╣рд╛рд▓рд╛ рдЖрдпреБрд╖реНрдпрд╛рдордзреНрдпреЗ рдЦреВрдк рд╕рдВрдШрд░реНрд╖ рдХрд░рд╛рд╡рд╛ рд▓рд╛рдЧрдд рдЕрд╕реЗрд▓, рддрд░ рд╕реНрд╡рддрдГрд▓рд╛ рдЦрд░рд╛ рдорд┐рддреНрд░.\n",
      "рд░рд╛рдЧрд╛рд▓рд╛ рдЬрд┐рдХрдВрдгреНрдпрд╛рдЪрд╛ рдПрдХрдореЗрд╡ рдЙрдкрд╛рдп тАУ рдореМрди . рдореЛрддреА рдмрдиреВрди рд╢рд┐рдВрдкрд▓реНрдпрд╛рдд рд░рд╛рд╣рдгреНрдпрд╛рдкреЗрдХреНрд╖рд╛ рджрд╡рдмрд┐рдВрджреВ рд╣реЛрдКрди рдЪрд╛рддрдХрд╛рдЪреА рддрд╣рд╛рди рднрд╛рдЧрд╡рд┐рдгреЗ рдЬрд╛рд╕реНрдд рд╢реНрд░реЗрд╖реНрда .\n",
      "рд╕реБрд░реБрд╡рд╛рдд рдХреБрдареВрди рдХрд░рд╛рд╡реА, рд╣реНрдпрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдд рдлреЗрд╕рд╛рд│рддреНрдпрд╛, рд▓рдк-рд▓рдкрдгрд╛рд░реНрдпрд╛ рд▓рд╛рдЯрд╛ рдкрд╛рдпрд╛рд╡рд░ рдШреЗрдд рдмрд╕рд▓реЗрд▓реЛ рдЬреНрдпрд╛ рд╣рд╛рдЪ рд╕реМрдЬрди рдирд╛рд╣реАрдирд╛ рдЖрдгрд┐ рдард░рд╡реВ рдирдпреЗрдд.\n",
      "рдиреЗрд╣рдд рдирд╛рд╣реА рддреБрдордЪреНрдпрд╛ рд╕реНрд╡рдкреНрдирд╛рдВрдЪрд╛ рдкрд╛рдард▓рд╛рдЧ рдХрд░рд╛ .\n",
      "рдореЛрдареНрдпрд╛ рд▓реЛрдХрд╛рдВрдЪреЗ рдЕрд╕рд╛рд▓ рддрд░ рджреЗрдК рдирдХрд╛ рдкрдг рдЖрд╢реНрд░рдп рджреЗрдКрди рдХрдЯреВ рд╢рдмреНрдж рдмреЛрд▓реВрди рд╡ рдХрд╛рдмрд╛рдбрдХрд╖реНрдЯ рдХрд░рд╡реВрди рдШреЗрдКрди рддреНрдпрд╛рдЪреНрдпрд╛ рд╢рд░реАрд░рд╛рд▓рд╛ рд╡ рдореМрдирд╛ рдХрдзреАрдЪ рд▓рд╛рдВрдм рдирд╕рддреЛ .\n",
      "рдкрд░рд┐рд╕реНрдерд┐рддреАрдЪреНрдпрд╛ рдЕрдзреАрди рд╣реЛрдК рдирдХрд╛, рдкрд░рд┐рд╕реНрдерд┐рддреАрд╡рд░ рдорд╛рдд рдХрд░рд╛.\n",
      "рдЖрдкрд▓реНрдпрд╛ рд╕рд╛рдзрдиреЗрдд рд╡реНрдпрддреНрдпрдп рддрд░ рдирд╛рд╣реАрдирд╛ рдЖрдгрд▓рд╛.\n",
      "рдПрдХрджрд╛ рдХрд░реНрддрд╡реНрдпрд╛рдЪреНрдпрд╛ рд╡рд╛рдЯреЗрд╡рд░реБрди рдЬрд╛рдпрдЪрдВ рдард░рд╡рд▓рдВ рдХреА рднрд╛рд╡рдирд╛рдВрдирд╛ рд╡рд┐рд╕рд░рд╛рдпрдЪрдВрдЪ рдЕрд╕рддрдВ .\n",
      "рдЖрд╡рдбрддрдВ рддреЗрдЪ рдХрд░реВ рдирдХрд╛, рдЬреЗ рдХрд░рд╛рд╡рдВ рд▓рд╛рдЧрддрдВ рддреНрдпрд╛рдд рдЖрд╡рдб рдирд┐рд░реНрдорд╛рдг рдХрд░рд╛.\n",
      "рдорд╛рддреА рд╕реМрдВрджрд░реНрдпрд╛рдкрд╛рд╕реВрди рдЬреАрд╡рд╛рд╕ рд╡рд┐рд╢реНрд░рд╛рдВрддреА рдЖрдгрд┐ рдордирд╛рдЪреА рдЙрдиреНрдирддреА рдЭрд╛рд▓реАрдЪ рдкрд╛рд╣рд┐рдЬреЗ.\n",
      "рдЬреЗ рдЭрд╛рд▓рдВ рддреНрдпрд╛рдЪрд╛ рд╡рд┐рдЪрд╛рд░ рдХрд░реВ рдирдХрд╛; рдЬреЗ рд╣реЛрдгрд╛рд░ рдЖрд╣реЗ рддреНрдпрд╛рдЪрд╛ рд╡рд┐рдЪрд╛рд░ рдХрд░рд╛.\n",
      "рдХрд┐рд╕реНрд╡рд╛рд░реНрдерд░рд╣реАрдд рдЖрдгрд┐ рдЦрд░реАрдЦреБрд░реА рд╕реЗрд╡рд╛ рд╣реАрдЪ рдЦрд░реА рдкреНрд░рд╛рд░реНрдердирд╛.\n",
      "рд╢рд┐рдХреНрд╖рдг рд╣реЗ рд╕рд╛рдзреНрдп рдирд╕реВрди рд╕рдорд╛рдзрд╛рди рдЖрд╣реЗ, рд╢рд┐рдХреНрд╖рдгрд╛рддреВрди рдирд╡рдЪреИрддрдиреНрдп, рдирд╡рд╕рдВрд╕реНрдХреГрддреА, рдирд╡рд╕рдорд╛рдЬ рдирд┐рд░реНрдорд╛рдг рдХрд░рд╛рд╡рдпрд╛рдЪрд╛ рдЖрд╣реЗ .\n",
      "рдорд╛рдгреВрд╕ рдЖрдкрд▓реНрдпрд╛ рдкрд░рд╛рдХреНрд░рдорд╛рдиреЗ рдПрдЦрд╛рджреНрдпрд╛ рд╡реЗрд│реЗрд▓рд╛ рдорд╣рддреНрддреНрд╡ рдЖрдгреВрди рджреЗрддреЛ .\n",
      "рдорд╛рдЭреНрдпрд╛\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(context, max_new_tokens=1200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sakharam can talk for forever until we press Cnt + C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "рдХрдерд╛ рд╡рд╕реНрддреВ рдЖрдХрд░реНрд╖рдХ рдЖрд╣реЗ.\n",
      "рд╕рдореБрджреНрд░рд╛рддреАрд▓ рддреБрдлрд╛рдирд╛рдкреЗрдХреНрд╖рд╛ рдордирд╛рддреАрд▓ рд╡рд╛рджрд│реЗ рдЕрдзрд┐рдХ рднрдпрд╛рдирдХ рдЕрд╕рддрд╛рдд .\n",
      "рдХрд┐рддреАрд╣реА рдореЛрдард╛ рдкрд╛рдард┐рдВрдмрд╛ рдЕрд╕рд▓рд╛ рддрд░реА рдпрд╢рд╕реНрд╡реА рддреЛрдЪ рд╣реЛрддреЛ рдЬреНрдпрд╛рдЪреНрдпрд╛ рд░рдХреНрддрд╛рддрдЪ рдЬрд┐рдВрдХрдгреНрдпрд╛рдЪреА\n",
      "\n",
      "рдЖрдкрдг рдкрдпреБрд╖реНрдпрд╛рдиреЗ рдЦрд╛рд░рдЪ рдХрд░рд╛рдпрдЪреЗ рдЕрд╕реЗрд▓ рддрд░ рдЖрдкрд▓реНрдпрд╛ рдЕрдирд╛рд╡рд╢реНрдпрдХ рдЧрд░рдЬрд╛ рд╡рд╛рдврдгрд╛рд░ рдирд╛рд╣реАрдд рдпрд╛рдЪреА рдХрд╛рд│рдЬреА рдШреНрдпрд╛.\n",
      "рдпрд╢ рди рдорд┐рд│рдгреЗ рдпрд╛рдЪрд╛ рдЕрд░реНрде рдЕрдкрдпрд╢реА рд╣реЛрдгреЗ рдЕрд╕рд╛ рдирд╛рд╣реА .\n",
      "рдореА рд╣реЗ рдорд╛рдирддреЗ рдХрд┐, рдлрдХреНрдд рдП\n",
      "\n",
      "рдЬреЛрдкрд░реНрдпрдВрдд рдЪрд╛рдВрдЧрд▓реЗ рд╢рд┐рдХреНрд╖рдг рдШреЗрдгреЗ рдореНрд╣рдгрдЬреЗ рдЪрд╛рдВрдЧрд▓реА рдиреЛрдХрд░реА рд▓рд╛рдЧрдгреЗ, рд╣рд┐ рд╕рдВрдХрд▓реНрдкрдирд╛ рдкрд╛рд▓рдХ рдЖрдгрд┐ рд╡рд┐рдзреНрдпрд╛рд░реНрдерд╛рдЪреНрдпрд╛ рдбреЛрдХреНрдпрд╛рддреВрди рдирд┐рдШрдд рдирд╛рд╣реА рддреЛрдкрд░реНрдпрдВрдд рд╕рдорд╛рдЬрд╛рдд рдиреЛрдХрд░рдЪ рдЬрдиреНрдорд╛рд▓рд╛ рдпреЗрддреАрд▓ рдорд╛рд▓\n",
      "\n",
      "рдХрд╛рд░рдг рддреА рд╡реНрдпрдХреНрддреА рд╕реНрд╡рддрд╛рдкреЗрдХреНрд╖рд╛ рддреБрдореНрд╣рд╛рд▓рд╛ рдЙрддреНрдХреГрд╖реНрдЯ рд╡реНрдпрдХреНрддреА рд╕рдордЬреВрди рдЬрд│рдд рдЕрд╕рддреЗ.\n",
      "рдЖрдЬрдЪреНрдпрд╛ рдЬрдЧрд╛рдд рд╡рд┐рд╢реБрджреНрдз рдкреНрд░реЗрдо рдХреБрдареЗрдЪ рдорд┐рд│рдд рдирд╛рд╣реА.\n",
      "рдПрдХрджрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдВрдЪреА рд╕рд╛рдЦрд│реА рд╕реБрд░реБ рдЭрд╛рд▓реА рдХрд┐, рддреН\n",
      "\n",
      "рдПрдХрджрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдВрдЪреА рд╕рд╛рдЦрд│реА рд╕реБрд░реБ рдЭрд╛рд▓реА рдХрд┐, рддреНрдпрд╛ рд╕рд╛рдЦрд│реАрдкреЗрдХреНрд╖рд╛ рд░рд╕реНрддрд╛ рдХрдзреАрдЪ рд▓рд╛рдВрдм рдирд╕рддреЛ .\n",
      "рдЬреЗрд╡реНрд╣рд╛ рдЖрдкрд▓реА рдирдЦрдВ рд╡рд╛рдврддрд╛рдд рддреЗрд╡реНрд╣рд╛ рдЖрдкрдг рдирдЦрдВ рдХрд╛рдкрддреЛ рдмреЛрдЯрдВ рдирд╛рд╣реА, рддреНрдпрд╛рдЪ рдкреНрд░рдпрддреНрди рдХрд░рддрд╛рдд \n",
      "\n",
      "рдорд╛рдгрд╕рд╛рдЪреА рдЪреМрдереА рдореВрд▓рднреВрдд рдЧрд░рдЬ рдореНрд╣рдгрдЬреЗ рдкреБрд╕реНрддрдХ.\n",
      "рддрд▓рд╡рд╛рд░реАрдЪреНрдпрд╛ рдЬреЛрд░рд╛рд╡рд░ рдорд┐рд│рд╡рд▓реЗрд▓реЗ рд░рд╛рдЬреНрдп рддрд▓рд╡рд╛рд░ рдЕрд╕реЗрддреЛрд╡рд░рдЪ рдЯрд┐рдХрддреЗ .\n",
      "рд╣реЗ рд╕реВрд░реНрдпрд╛рдиреЗ рдХрд╛рдЬрд╡реНрдпрд╛рдВрдЪреЗ рд╕реНрдорд░рдг рдареЗрд╡рдгреНрдпрд╛ рд╕рд╛рд░рдЦреЗ рдЖрд╣реЗ.\n",
      "рддрд▓рд╡рд╛рд░ рд╣\n",
      "\n",
      "рд╣реЗ рд╕реВрд░реНрдпрд╛рдиреЗ рдХрд╛рдЬрд╡реНрдпрд╛рдВрдЪреЗ рд╕реНрдорд░рдг рдареЗрд╡рдгреНрдпрд╛ рд╕рд╛рд░рдЦреЗ рдЖрд╣реЗ.\n",
      "рддреБрдордЪреА рдкреНрд░рддрд┐рд╖реНрдард╛ рдЬреЗрд╡рдвреА рдореЛрдареА рддреЗрд╡рдвреАрдЪ рддреБрдордЪреА рдмрджрдирд╛рдореА рдЬрд╛рд╕реНрдд.\n",
      "рдкрд░рд│рдХреНрд╖рд╛ рдЖрдзреА рдХреЗрд▓реЗ рдкрд╛рд╣рд┐рдЬреЗ.\n",
      "рд╕рд╛рдХрд▓реНрдпрд╛рдиреЗ рдорд┐рд│рдгрд╛рд░реЗ рд╕рдорд╛рдзрд╛\n",
      "\n",
      "рдирд╛рддреА рдХрд┐рддреАрд╣реА рд╡рд╛рдИрдЯ рдЕрд╕реВ рджреЗ рддреА рдХрдзреАрд╣реА рддреЛрдбреВ рдирдХрд╛ рдХрд╛рд░рдг рдкрд╛рдгреА рдХрд┐рддреАрд╣реА рдШрд╛рдг рдЕрд╕рд▓рдВ рддрд░реА рддреЗ рддрд╣рд╛рди рдирд╛рд╣реА рддрд░ рдЖрдЧ рддрд░реА рд╡рд┐рдЭрд╡реБ рд╢рдХрддреЗ.\n",
      "рдирд┐рджрд╛рди рдкрд╛рд╕рд╖реНрдЯ рдкреНрд░рддрд┐рд╢рдд рддрд░реА рдЕрд╕рд╛рд╡реЗрдд.\n",
      "рдЬрд╛рддреАрдкрд╛рддреА рд╕\n",
      "\n",
      "рдЬреЗ рдЕрдВрдЧрд╛ ред рдЬрдЧрд╛рдд рд╡рд┐рд╢реБрджреНрдз рдкреНрд░реЗрдо рдХреБрдареЗрдЪ рдорд┐рд│рдд рдирд╛рд╣реА.\n",
      "рд╕реВрдб рдШреЗрдгреНрдпрд╛рдкреЗрдХреНрд╖рд╛ рдХреНрд╖рдорд╛ рдХрд░рдгреЗ рдЕрдзрд┐рдХ рдЪрд╛рдЧрдВрд▓реЗ.\n",
      "рдПрдХрджрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдВрдЪреА рд╕рд╛рдЦрд│реА рд╕реБрд░реБ рдЭрд╛рд▓реА рдХрд┐, рддреНрдпрд╛ рд╕рд╛рдЦрд│реАрдкреЗрдХреНрд╖рд╛ рд░рд╕реНрддрд╛ рдХрдзреАрдЪ \n",
      "\n",
      "рддреНрдпрд╛рдВрдиреА рдорд╛рдЭреЗ рд▓рдЧреНрди рдХрд░рд╛рдпрдЪреЗ рдХреБрдЯреАрд▓ рдХрд╛рд░рд╕реНрдерд╛рди рд░рдЪрд▓реЗ рдЖрд╣реЗ.\n",
      "рдкреНрд░рд╕рд┐рдзреНрджреА рд╣реА рдЕрд╢реА рдмрд╛рдм рдЖрд╣реЗ рдЬреА рдХрд┐рддреАрд╣реА рдорд┐рд│рд╛рд▓реА рддрд░реА рдорд╛рдгрд╕рд╛рдЪреА рддрд╣рд╛рди рднрд╛рдЧрдд рдирд╛рд╣реА.\n",
      "рдкрд╛рддреНрд░ рдирд┐рд░реНрдорд┐рддреА рд╡рд┐рд▓реЛрднрдиреАрдп рдЖрд╣реЗ.\n",
      "рдн\n",
      "\n",
      "рдпрд╛ рдкреБрдвреЗ рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдореА рдХрд╕рд▓реАрдЪ рддрд╕рджреА рджреЗрдгрд╛рд░ рдирд╛рд╣реА.\n",
      "рдЦрд░рдВ рдЖрдгрд┐ рдЦреЛрдЯрдВ рдпрд╛рдд рдХреЗрд╡рд│ рдЪрд╛рд░ рдмреЛрдЯрд╛рдВрдЪрдВ рдЕрдВрддрд░ рдЖрд╣реЗ.\n",
      "рднреБрддрдХрд╛рд│ рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдЖрдард╡рдгреАрдВрдЪрд╛ рдЖрдирдВрдж рджреЗрддреЛ; рднрд╡ рдирдХрд╛ рдЬрдиреНрдо рдареЗрд╡рд╛,  рдкрд╛рдгреНрдпрд╛рдЪрд╛\n",
      "\n",
      "рдкрд╛рд╡рд╕рд╛рдЪреНрдпрд╛ рдПрдХрд╛ рд╕рд░реАрдиреЗ рдЬрд░ рдзрд░рддреА рддреГрдкреНрдд рд╣реЛрдКрди рдорд╛рдгрд╕рд╛рдЪреА рд╕реНрд╡рд░реВрдкрд╛рдХрд╛рд░ рдШреЗрддреЛ.\n",
      "рдкрд╛рд╣рд┐рд▓реЗрд▓реНрдпрд╛ рдкрд╛рд╡рд╕рд╛рд│реНрдпрд╛рдкреЗрдХреНрд╖рд╛ рдЕрдиреБрднрд╡рд▓реЗрд▓реЗ рдкрд╛рд╡рд╕рд╛рд│реЗ рдЕрдзрд┐рдХ рдорд╣рддреНрддреНрд╡рд╛рдЪреЗ рдЕрд╕рддрд╛рдд.\n",
      "рдкреНрд░рдпрд╛рд╕ рд╣рд╛ рдкреНрд░рддрд┐рднреЗрдЪ\n",
      "\n",
      "рдирд┐рджрд╛рди рдкрд╛рд╕рд╖реНрдЯ рдкреНрд░рддрд┐рд╢рдд рддрд░реА рдЕрд╕рд╛рд╡реЗрдд.\n",
      "рдирд┐рджрд╛рди рдкрд╛рд╕рд╖реНрдЯ рдкреНрд░рддрд┐рд╢рдд рддрд░реА рдЕрд╕рд╛рд╡реЗрдд.\n",
      "рдкрд╛рдгреНрдпрд╛рдЪрд╛ рдПрдХ рдереЗрдВрдм рдЪрд┐рдЦрд▓рд╛рдд рдкрдбрд▓рд╛ рддрд░ рддреЛ рд╕рдВрдкрддреЛ, рд╣рд╛рддрд╛рд╡рд░ рдкрдбрд▓рд╛ рддрд░ рдЪрдордХрддреЛ, рд╢рд┐рдВрдкрд▓реНрдпрд╛рддрд▓реНрдпрд╛ рдХреЛрдгрддреНрдп\n",
      "\n",
      "рджреБрдмрд│реА рдорд╛рдгрд╕реЗ рд░рдбрдЧрд╛рдгреА рд╕рд╛рдВрдЧрдгреНрдпрд╛рд╕рд╛рдареАрдЪ рдЬрдиреНрдорд╛рд▓рд╛ рдЖрд▓реЗрд▓реА рдЕрд╕рддреЗ рдЖрдгрд┐ рд╣реГрджрдп рд╣рд░реВрдирджреЗрдЦреАрд▓ рдЬрд┐рдВрдХрд▓реЗрд▓рдВ рдЕрд╕рддрдВ.\n",
      "рд╕рд╛рдХрд▓реНрдпрд╛рдиреЗ рдорд┐рд│рдгрд╛рд░реЗ рд╕рдорд╛рдзрд╛рди.\n",
      "рдорд╛рдгрд╕рд╛рдЪреА рдЪреМрдереА рдореВрд▓рднреВрдд рдЧрд░рдЬ рдореНрд╣рдгрдЬреЗ рдкреБрд╕реНрддрдХ.\n",
      "\n",
      "рдЬреАрд╡рдирд╛рддреАрд▓ рдкреНрд░рддреНрдпреЗрдХ рдШрдЯрдиреЗрд▓рд╛ рдЕрд░реНрде рдЕрд╕рддреЛ.\n",
      "рдЗрдЪреНрдЫрд╛ рджрд╛рдВрдбрдЧреА рдЕрд╕рд▓реА рдХреА рдорджрдж рдЖрдкрдгрд╣реВрди рддреБрдордЪреНрдпрд╛рдХрдбреЗ рдЪрд╛рд▓рдд рдпреЗрддреЗ.\n",
      "рдорд╛рдЭреНрдпрд╛ рдЬреАрд╡рдирд╛рдд рдПрдХ рдирд╡реЗ рдкрд░реНрд╡ рд╕реБрд░реБ рд╣реЛрдд рдЖрд╣реЗ.\n",
      "рдЕрдбреНрдпрд╛рд╡рд░ рдмрдШреЗ.\n",
      "рдХрд╛рд░рдг рддреА\n",
      "\n",
      "рд╡реГрдХреНрд╖рд╛рдиреЗ рдирд┐рд╕рд░реНрдЧрд╛рдЪрд╛ рд╕рдорддреЛрд▓ рд░рд╛рд╣рд╛рддреЛ.\n",
      "рд╣реЗ рдореА рдЖрдкрд▓реНрдпрд╛рд╡рд░ рд╕реЛрдкрд╡рддреЛ.\n",
      "рд╡ рдорд░рддрд╛рдирд╛рд╣реА рдкрд╛рд╣рдгрд╛рд░ рдирд╛рд╣реАрдд.\n",
      "рд╕рд╛рдХрд▓реНрдпрд╛рдиреЗ рдорд┐рд│рдгрд╛рд░реЗ рд╕рдорд╛рдзрд╛рди.\n",
      "рдЦреВрдк рдорд╛рдгрд╕рд╛рдВрдЪреА рд╕реНрд╡рдкреНрдиреЗ рдпрд╛ рдПрдХрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдореБрд│реЗ рдЕрдкреВрд░\n",
      "\n",
      "рдорд╛рдгреВрд╕ рдЖрдгрд┐ рдкреНрд░рд╛рдгреА рдпрд╛рдВрдЪреНрдпрд╛рдд рдлрд░рдХ рдЖрд╣реЗ рдХрд╛рд░рдг рдкрд░рдореЗрд╢реНрд╡рд░рд╛рдиреЗ рддреНрдпрд╛рдВрдирд╛ рд╡рд╛рдЪрд╛ рдЖрдгрд┐ рдмреБрджреНрдзреА рдЕрд╢рд╛ рджреЛрди рдЕрдореГрдд рдареЗрд╡рд╛.\n",
      "рдЬрдЧреВ рд╢рдХрд▓рд╛рдд рддрд░ рдЪрдВрджрдирд╛рд╕рд╛рд░рдЦреЗ рдЬрдЧрд╛; рд╕реНрд╡рдд: рдЭреАрдЬрд╛ рдЖрдгрд┐ рдЗрддрд░рд╛рдВрдирд╛ рдЧрдВрдз \n",
      "\n",
      "рдкреНрд░реЗрдо рд╕рд░реНрд╡рд╛рдВрд╡рд░ рдХрд░рд╛.\n",
      "рдирд┐рдпрдорд┐рддрдкрдгрд╛ рд╣рд╛ рдорд╛рдгрд╕рд╛рдЪрд╛ рд╕рд░реНрд╡рд╛рдд рдореЛрдард╛ рд╢рддреНрд░реВ рдЖрд╣реЗ.\n",
      "рдЕрд╕рд╛ рд╡реНрдпрд╛рд╕рдВрдЧ рдХрд░рд╛рдпрдЪреА рдЗрдЪреНрдЫрд╛ рдЖрд╣реЗ рдорд╛рдЭреА.\n",
      "рдпрд╢ рд╕рд╛рдЬрд░рдВ рдХрд░рдгрдВ рдареАрдХ рдЖрд╣реЗ рдкрдг рддреНрдпрд╛рдкреЗрдХреНрд╖рд╛ рдорд╣рддреНрд╡рд╛рдЪрдВ рдЖрд╣реЗ рдЕрдк\n",
      "\n",
      "рдЖрдкрд▓реНрдпрд╛рдореБрд│реЗ рджреБрд╕рд▒реНрдпрд╛рд▓рд╛ рджреБрдЦ рд╣реЛрдИрд▓ рдЕрд╕реЗ рдХрдзреАрд╣реА рд╡рд╛рдЧреВ рдирдХрд╛.\n",
      "рдЖрдпреБрд╖реНрдпрд╛рдд рдЖрдЬрд╡рд░ рдЬрдЧрд▓реЛ, рдкреНрд░реЗрдо рдХреЗрд▓рдВ, рд╣рд░рд▓реЛ, рдЪреБрдХрд▓реЛ, рджреБрдЦрд╛рд╡рд▓реЛ, рд╡рд┐рд╢реНрд╡рд╛рд╕ рдЯрд╛рдХрд▓рд╛, рдЪреБрдХрд╛ рдХреЗрд▓реНрдпрд╛, рдкрдг рдкреНрд░рддреНрдпреЗрдХрд╡реЗрд│реА рдореА\n",
      "\n",
      "рдореА рдЖрдкрдгрд╛рд╢реА рдкреНрд░рддрд╛рд░рдгрд╛ рдХрд░реВ рдЗрдЪреНрдЫрд┐рдд рдирд╛рд╣реА.\n",
      "рдЖреИрд╢рд╛рдиреЗ рд╡ рдЧреБрд░реБрдЬрди рд╡ рджреЗрд╢ рдпрд╛рдВрдЪреНрдпрд╛рд╡рд░ рдирд┐рд╖реНрдард╛ рдареЗрд╡рд╛рд╡рд▓рд╛рдЪ рд╣рд╡реА.\n",
      "рдЬреНрдпрд╛рд▓рд╛ рдЖрднрд╛рд│рд╛рдЪреА рддреБрдбрд╡реГ рд▓рд╛рдЧрддреЛ.\n",
      "рдорд▓рд╛ рдЬреАрд╡рдирд╛рдиреБрднреВрддреА рд╣реЛрдд рдирд╛рд╣реА рдЖрд╣реЗ.\n",
      "рдирд┐рд╕\n",
      "\n",
      "рдЕрд╕рддреНрдп рд╣реЗ рдЕрдкрдВрдЧ рдкреНрд░рд╛рдгреНрдпрд╛рдкреНрд░рдорд╛рдгреЗ рдЕрд╕рддреЗ, рджреБрд╕рд▒реНрдпрд╛рдЪреНрдпрд╛ рдЖрдзрд╛рд░рд╛рд╢рд┐рд╡рд╛рдп рддреЗ рдХрдзреАрдЪ рдЙрднреЗ рд░рд╛рд╣реВ рд╢рдХрдд рдирд╛рд╣реА.\n",
      "рдЬреАрд╡рдирд╛рдЪреНрдпрд╛ рд╕рдорд░рд╛рдд рд░рдХреНрддрдмрдВрдмрд╛рд│ рд╡реНрд╣рд╛рдпрдЪреЗ рдкреНрд░рд╕рдВрдЧ рдпрд╛рдпрдЪреЗрдЪ.\n",
      "рдЕрдЪрд╛рд░рд╛рдЪрд╛ рджрд░рд╡рд╛рдЬрд╛ \n",
      "\n",
      "рд░рд╛рддреНрд░реАрдЪрд╛ рджрд┐рд╡рд╕ рдХрд░реВрди рдЖрдкрд▓реНрдпрд╛ рдЕрдиреБрдЬреНрдЮреЗ рдкреНрд░рдорд╛рдгреЗ рдореА рдкреБрд╕реНрддрдХреЗ рд╡рд╛рдЪреВрди рдХрд╛рдврд▓реА\n",
      "рдорд╛рдгрд╕рд╛рд▓рд╛ рджреЛрдирдЪ рдЧреЛрд╖реНрдЯреА рд╣реБрд╢рд╛рд░ рдмрдирд╡рддрд╛рдд .\n",
      "рдЦреВрдк рдорд╛рдгрд╕рд╛рдВрдЪреА рд╕реНрд╡рдкреНрдиреЗ рдпрд╛ рдПрдХрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдореБрд│реЗ рдЕрдкреВрд░реНрдг рд░рд╛рд╣рдд\n",
      "\n",
      "рд╡рд╛рд╣рддреЛ рддреЛ рдЭрд░рд╛ рдЖрдгрд┐ рдерд╛рдВрдмрддреЗ рддреЗ рдбрдмрдХрдВ. рдбрдмрдХреНрдпрд╛рд╡рд░ рдбрд╛рд╕ рдпреЗрддрд╛рдд рдЖрдгрд┐ рдЭрд▒реНрдпрд╛рд╡рд░ рд░рд╛рдЬрд╣рдВрд╕. рдЧреЛрд╖реНрдЯреА рдХрд░рд╛ .\n",
      "рдорд▓рд╛ рдХреНрд╖рдорд╛ рдХрд░рд╛.\n",
      "рдЙрджреНрдпрд╛рдЪрд╛ рднрд╡рд┐рд╖реНрдпрдХрд╛рд│ рд╡рд░реНрддрдорд╛рдирд╛рдЪреНрдпрд╛ рддреНрдпрд╛рдЧрд╛рддреВрди рдирд┐рд░реНрдорд╛рдг рд╣\n",
      "\n",
      "рдкрдг рдЬреЗрд╡реНрд╣рд╛ рддреБрдореНрд╣реА рдХрд╛рд▓рд╛рдВрддрд░рд╛рдиреЗ рдорд╛рдЧреЗ рд╡рд│реВрди рдкрд╛рд╣рд╛рд▓ рддреЗрд╡реНрд╣рд╛ рддреБрдореНрд╣рд╛рд▓рд╛ рдЬрд╛рдгреАрд╡ рд╣реЛрддреЗ рдХрд┐ рддреБрдореНрд╣реА рдХрд┐рддреА рднрд╛рд╡рдирд╛ рдирд╕рддрдЪ рдХрд┐рддреА рд╢реНрд░реЗрд╖реНрда .\n",
      "рдорд╛рдЭреНрдпрд╛ рдпрд╛ рдореБрдЧреНрдз рд╡рд╛рдХреНрдпрд╛рд▓рд╛ рд╣рд╕рдгреЗ рд╕рд╛рд╣рдЬрд┐рдХ рдЖ\n",
      "\n",
      "рдПрдХрдЪ рдирд╛рд╣реА рдореНрд╣рдгрдЬреЗ рд╡рд╛рдЪрд▓реЗрд▓реА рдкреБрд╕реНрддрдХрдВ рдЖрдгрд┐ рджреБрд╕рд░реА рднреЗрдЯрд▓реЗрд▓реА рдорд╛рдгрд╕рдВ.\n",
      "рдореНрд╣рдгреВрди рдорд╛рдЬреВ рдирдХрд╛ .\n",
      "рд░рд╛рддреНрд░реАрдЪрд╛ рджрд┐рд╡рд╕ рдХрд░реВрди рдЖрдкрд▓реНрдпрд╛ рдЕрдиреБрдЬреНрдЮреЗ рдкреНрд░рдорд╛рдгреЗ рдореА рдкреБрд╕реНрддрдХреЗ рд╡рд╛рдЪреВрди рдХрд╛рдврд▓реА\n",
      "рднрд┐рддреАрдпреБрдХреНрдд \n",
      "\n",
      "рджрд╛рди рдкрд╛рд░реНрдЧрд╛рд╕рд╛рд░рдЦреЗ рдЕрд╕рддрд╛рдд рдкрдг рддреБрдореНрд╣реА рддрд┐рдЪреНрдпрд╛ рдкрд╛рдпрд╛рд▓рд╛ рдЪрд╛рд╡реВ рд╢рдХрдд рдирд╛рд╣реА, рдореНрд╣рдгреВрдирдЪ рдЬреАрд╡рдирд╛рдд рдХреБрдгрд╛рд▓рд╛рдЪ рдЫреЛрдЯ рд╕рдордЬреВ рдирдХрд╛ рдХрд╛рд░рдг рддреЗ рдЬреЗ рдХрд░реВ рд╢рдХрддреЗ рдХрджрд╛рдЪрд┐рдд рддреЗ рдЬреНрдЮрд╛рди рд╣рд╡рдВ.\n",
      "рдЙрддреНрддреЗрдЬрдХ рдкреЗрдпрд╛\n",
      "\n",
      "рдЖрд▓рд╛ рдЬрд╛рддрд╛рдЪреА рддреЛрдбреВрди рддреНрдпрд╛рдВрдирд╛  рддреНрдпрд╛рдВрдЪрда рдирд┐рдХрд╛рд▓ рд▓рд╛рд╡рдгреНрдпрд╛рдЪреЗ рд╕рд╛рдорд░реНрдереНрдп рд╕реНрд╡рддрдГ рдЬрд╡рд│ рдареЗрд╡рд╛.\n",
      "рдорд╛рдгреВрд╕ рджреБрд╕рд▒реНрдпрд╛рд▓рд╛ рдХрд┐рддреАрд╣реА рдлрд╕рд╡рд┐рдгрд╛рд░рд╛рд╕ рддреНрдпрд╛рдЪреА рдЖрджрд░реЛрдЧрд▓реА рдореВрд░реНрдЦ рдорд╛рдгрд╕реЗ рдЖрдкрд╛рдкрд╕рд╛рдд рд╕рдВрднрд╛рд╖рдг \n",
      "\n",
      "рдЬреАрд╡рдирд╛рддреАрд▓ рдХрд╛рд╣реА рдкрд░рд╛рднрд╡ рд╣реЗ рд╡рд┐рдЬрдпрд╛рд╣реВрдирд╣реА рдЕрдзрд┐рдХ рд╢реНрд░реЗрд╖реНрда рдЕрд╕рддрд╛рдд.\n",
      "рд╣реЗ рд╡рд╛рдХреНрдп рдорд▓рд╛ рдЖрдкрд▓реЗ рдЬреАрд╡рди рд╡рд┐рд╖рдпрдХ рд╕реВрддреНрд░ рд╡рд╛рдЯрддреЗ.\n",
      "рдФрджрд╛рд░реНрдп рдореНрд╣рдгрдЬреЗ рддреБрдордЪреНрдпрд╛ рдХреНрд╖рдорддреЗрдкреЗрдХреНрд╖рд╛ рдЕрдзрд┐рдХ рджреЗрдгрдВ рдЖрдгрд┐ рдЖрддреНрдорд╕\n",
      "\n",
      "рд╕рдореБрджреНрд░рд╛рддреАрд▓ рддреБрдлрд╛рдирд╛рдкреЗрдХреНрд╖рд╛ рдордирд╛рддреАрд▓ рд╡рд╛рджрд│реЗ рдЕрдзрд┐рдХ рднрдпрд╛рдирдХ рдЕрд╕рддрд╛рдд .\n",
      "рдкрд░рд┐рд╕реНрдерд┐рддреАрдЪреНрдпрд╛ рдЕрдзреАрди рд╣реЛрдК рдирдХрд╛, рдкрд░рд┐рд╕реНрдерд┐рддреАрд╡рд░ рдорд╛рдд рдХрд░рд╛.\n",
      "рд╣реЗ рджреЗрд╡рд╛, рдорд▓рд╛ рдЦреВрдк рдЦреВрдк рдЖрд╡реНрд╣рд╛рдирдВ рджреЗ рд╡ рддреА рдкреЗрд▓рдгреНрдпрд╛рд╕\n",
      "\n",
      "рд╢реЗрд╡рдЯрдкрд░реНрдпрдВрдд рдЬреЗ рдкреНрд░рдпрддреНрди рдХрд░рдд рд░рд╛рд╣рддрд╛рдд рддреНрдпрд╛рдирд╛рдВрдЪ рдпрд╢ рдкреНрд░рд╛рдкреНрдд рд╣реЛрддреЗ.\n",
      "рд╕реБрдЯреНрдЯреА рд╣реА рддреЛ рдЧрд░реВрдбрд╛рдЗрддрдХреЗ рдЙрдбрддрд╛ рдпреЗрдд рдирд╛рд╣реА рдореНрд╣рдгреВрди рдЪрд┐рдордгреА рдХрдзреА рдЙрдбрдгреНрдпрд╛рдЪреЗ рд╕реЛрдбрдд рдирд╛рд╣реА .\n",
      "рдПрдХрджрд╛ рдХрд╛ рд╡рд┐рдЪрд╛рд░рд╛рдВрдЪ\n",
      "\n",
      "рдорд░рддрд╛рдирд╛ рдЖрдкрдг рдЕрд╕рдВ рдорд░рд╛рд╡рдВ рдХреА рдЖрдкрдг рд╣рд╕рдд рдЕрд╕реВ рдЖрдгрд┐ рд▓реЛрдХ рд░рдбрдд рдЕрд╕рддреАрд▓ .\n",
      "рдкреНрд░рддрд┐рдХреВрд▓рддреЗрддрд╣реА рдЕрдиреБрдХреВрд▓рддрд╛ рдирд┐рд░реНрдорд╛рдг рдХрд░рддреЛ рддреЛрдЪ рдЦрд░рд╛ рдорд╛рдгреВрд╕. рдкреНрд░рддрд┐рднрд╛ рд╣реА рдЕрдирдВрдд рдкрд░рд┐рд╢реНрд░рдорд╛рдд рд╕рд╛рдорд╛рд╡рд▓реЗрд▓реА рдЕрд╕рддреЗ .\n",
      "\n",
      "\n",
      "рдЖрдкрддреНрддреА рдореНрд╣рдгрдЬреЗ рдЖрдкрд▓рд╛ рд╕рд░реНрд╡рд╛рдд рдореЛрдард╛ рдЧреБрд░реБ .\n",
      "рд╣реЗ рд╡рд╛рдХреНрдп рдорд▓рд╛ рдЖрдкрд▓реЗ рдЬреАрд╡рди рд╡рд┐рд╖рдпрдХ рд╕реВрддреНрд░ рд╡рд╛рдЯрддреЗ.\n",
      ". рдХреБрдгрд╛рдЪреНрдпрд╛рд╣реА рд╡рдпрд╛рдЪрд╛ рдЕрдиреБрдн рдХрд░реВ рдирдХрд╛;  рдЬреЗ рдХрд░рд╛рд╡рдВ рд▓рд╛рдЧрддрдВ рддреНрдпрд╛рдд рдЖрд╡рдб рдирд┐рд░реНрдорд╛рдг рдХрд░рд╛\n",
      "\n",
      "рдорд▓рд╛ рдХреНрд╖рдорд╛ рдХрд░рд╛.\n",
      "рджреБрдГрдЦрд╛рдЪреА рдЪрд╡ рдШреЗрдгреНрдпрд╛рдкреЗрдХреНрд╖рд╛ рддреЗ рдкрдЪрд╡рдгреНрдпрд╛рдд рдЕрдзрд┐рдХ рдЧреЛрдбреА рдЖрд╣реЗ.\n",
      "рд╕рд╛рд╣рд┐рддреНрдпрд╛рд╢реА рдПрдХрдирд┐рд╖реНрда рд░рд╛рд╣рд╛.\n",
      "рдЖрд╡рдбрддрдВ рддреЗрдЪ рдХрд░реВ рдирдХрд╛.\n",
      "рдордиреБрд╖реНрдпрд╛рдЪреЗ рдореЛрдареЗрдкрдг рд╣реЗ рддреНрдпрд╛рдЪреНрдпрд╛ рд╡рдпрд╛рд╡рд░ рдирд╡реНрд╣реЗ\n",
      "\n",
      "рдЖрдгрд┐ рдЬреАрд╡рдирд╛рд╢реАрд╣реА.\n",
      "рд╕рд░реНрд╡ рдЧреЛрд╖реНрдЯреАрдВрдирд╛ рдкреБрд░реВрди рдЙрд░рдгрд╛рд░реА рдПрдХрдЪ рдЧреЛрд╖реНрдЯ рдЖрд╣реЗ .\n",
      "рдкрд╛рддреНрд░ рдирд┐рд░реНрдорд┐рддреА рд╡рд┐рд▓реЛрднрдиреАрдп рдЖрд╣реЗ.\n",
      "рдмреБрдбрдгрд╛рд▒реНрдпрд╛рдВрдирд╛ рдХрд┐рдирд╛рд▒реНрдпрд╛рд╡рд░реБрди рд╕реВрдЪрдирд╛ рджреЗрддрд╛рдд рддреЗ рд╕рд╛рдорд╛рдиреНрдп рдЖрдгрд┐ рд╕рдмрд▓рддрд╛ рд╣рд╛ \n",
      "\n",
      "рдЬрд░ рддреБрдореНрд╣реА рддреНрдпрд╛ рд╡реНрдпрдХреНрддреАрдЪреА рд╡рд╛рдЯ рдкрд╛рд╣рдд рдЕрд╕рд╛рд▓ рдЬреА рддреБрдордЪреЗ рдЬреАрд╡рди рд╡рд╛рдЪрд╡рдгрд╛рд░ рдЖрд╣реЗ, рддрд░ рддреБрдореНрд╣рд╛рд▓рд╛ рдлрдХреНрдд рдЖрд░рд╢рд╛рдд рдмрдШрдгреНрдпрд╛рдЪреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдЖрд╣реЗ .\n",
      "рдЖрд╢рд╛ рд╣реА рддреЗрдЬрд╢реНрд░реА рдЖрд╣реЗ.\n",
      "рдкрд╛рддреНрд░ рдирд┐рд░реНрдорд┐рддреА рд╡рд┐\n",
      "\n",
      "рд╕рд░реНрд╡рд╛рдд рдореЛрдард╛ рд░реЛрдЧ рдХрд╛рдп рдореНрд╣рдгрддреАрд▓ рд▓реЛрдХ.\n",
      "рдкреНрд░рддрд┐рдХреВрд▓рддреЗрддрд╣реА рдЕрдиреБрдХреВрд▓рддрд╛ рдирд┐рд░реНрдорд╛рдг рдХрд░рддреЛ рддреЛрдЪ рдЦрд░рд╛ рдорд╛рдгреВрд╕. рдкреНрд░рддрд┐рднрд╛ рд╣реА рдЕрдирдВрдд рдкрд░рд┐рд╢реНрд░рдорд╛рдд рд╕рд╛рдорд╛рд╡рд▓реЗрд▓реА рдЕрд╕рддреЗ .\n",
      "рдирд┐рджрд╛рди рдкрд╛рд╕рд╖реНрдЯ рдкреНрд░рддрд┐рд╢рдд рддрд░\n",
      "\n",
      "рддреНрдпрд╛рдиреЗ рдЬреЗ рджрд┐рд▓реЗ рдЖрд╣реЗ рддреНрдпрд╛рдмрджреНрджрд▓ рддреНрдпрд╛рдЪреЗ рдЖрднрд╛рд░ рдорд╛рдирд╛.\n",
      "рдирд┐рд╖реНрдареЗрдиреЗ рдЬреЗ рдЖрдкрд▓реА рдХрд╛рд░реНрдпреЗ рдХрд░рддрд╛рддтАж .\n",
      "рдкреНрд░рд╛рдЬреНрдЮ рдкрд░реАрдХреНрд╖реЗрдд рдкрд╛рд╕ рдЭрд╛рд▓реЛ.\n",
      "рдЬреНрд╡рд╛рдЪрдВ рдорди рдЬрд│рдгреА рдЬреЛ рдЖрдкрд▓реНрдпрд╛ рдордирд╛рдХрд░реАрддрд╛ рдорд░рдгрд╛рдмрд░реЛрдмрд░\n",
      "\n",
      "рдореЛрддрд╛ рдЖрдгрд┐  рдПрдЦрд╛рджреНрдпрд╛ рдорд╛рдгрд╕рд╛рдЪреА рд╕реЛрдмрдд рдЖрд╣реЗ рддреНрдпрд╛рд▓рд╛ рдХреЛрдгрддреЗрд╣реА рдЕрдВрддрд░ рд▓рд╛рдВрдм рд╡рд╛рдЯрдд рдирд╛рд╣реА .\n",
      "рдЙрдЪреНрдЪреАрдд рдзреНрдпреЗрдпрд╛рдЪреНрдпрд╛ рдЙрджреНрджрд┐рд╖реНрдЯрдкреВрд░реНрддреАрдХрдбреЗ рд╣реЛрдгрд╛рд░реА рд╡рд╛рдЯрдЪрд╛рд▓ рдореНрд╣рдгреЗ рддрд░ рдЖрдкрд▓реНрдпрд╛ рд╡рд╛рдЯреНрдпрд╛рд▓рд╛ рдЖрд╣реЗ\n",
      "\n",
      "рдЖрдкрд▓реНрдпрд╛ рдкрд╣рд┐рд▓реНрдпрд╛ рднреЗрдЯреАрддреАрд▓ рджрд┐рд▓реЗрд▓реА рд╕реНрд╡рд╛рдХреНрд╖рд░реА рдореА рдЖрдЬрд╣реА рд╡рд╛рдЪрддреЛ.\n",
      "рдЬреНрдпрд╛рд▓рд╛ рдХрд╛рдп рд▓рд┐рд╣рд╛рд╡рдВ рдпрд╛рдкреЗрдХреНрд╖рд╛ рдХрд╛рдп рд▓рд┐рд╣реВ рдирдпреЗ рд╣реЗ рдХрд│рддрдВ рддреЛрдЪ рдЦрд░рд╛ рд▓реЗрдЦрдХ .\n",
      "рд╕реНрд╡рддрдГрд╡рд░ рдмрд╕рд▓рд╛ рдмрд╛рдЬреВ рдирдХрд╛, рд╕реНрд╡рддрдГрдЪрд╛ рдо\n",
      "\n",
      "рдПрдХрджрд╛ рдХрд░реНрддреГрддреНрд╡ рд╕рд┐рджреНрдз рдЭрд╛рд▓рдВ рдХрд┐, рд╕рдВрд╢рдпрд╛рдиреЗ рдмрдШрдгрд╛рд▒реНрдпрд╛ рдирдЬрд░рд╛ рдЖрдкреЛрдЖрдк рдЖрджрд░рд╛рдирдВ рдЭреБрдХрддрд╛рдд.\n",
      "рдЙрддреНрддреЗрдЬрдХ рдкреЗрдпрд╛рдВрдкрд╛рд╕реВрди рдореА рдкрд╣рд┐рд▓реНрдпрд╛ рдкрд╛рд╕реВрдирдЪ рдЕрд▓рд┐рдкреНрдд рдЖрд╣реЗ.\n",
      "рдЬреЗ рдЖрд╡рдбрддрд╛рдд рддреНрдпрд╛рдВрдЪреНрдпрд╛рд╡рд░ рдкреНрд░реЗрдо рдХ\n",
      "\n",
      "рдорд▓рд╛ рдХреНрд╖рдорд╛ рдХрд░рд╛.\n",
      "рдореБрдХреНрдпрд╛ рдкреНрд░рд╛рдгреНрдпрд╛рдВрд╡рд░ рд╕рджреИрд╡ рдкреНрд░реЗрдо рдХрд░рд╛.\n",
      "рдзрдИрдЯреНрдЯ рд╣реЛрдКрди рдиреЗрд╣рдореА рдЙрддреНрдХреГрд╖реНрдЯ рдХрд▓рд╛рдХрд╛рд░рд▓рд╛ рджреЗрддреЛтАж .\n",
      "рдЭрд╛рдбрд╛рд╡рд░ рдкреНрд░реЗрдо рдЕрд░реНрдкрд╛рдкреНрд░рдмрд│ рдЕрд╕рддреЛ.\n",
      "рд╣реЗ рд╡рд╛рдХреНрдп рдорд▓рд╛ рдЖрдкрд▓реЗ рдЬреАрд╡рди рд╡рд┐рд╖рдп\n",
      "\n",
      "рдпрд╛ рдкреБрдвреЗ рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдореА рдХрд╕рд▓реАрдЪ рддрд╕рджреА рджреЗрдгрд╛рд░ рдирд╛рд╣реА.\n",
      "рд╡рд╛рд╣рддреЛ рддреЛ рдЭрд░рд╛ рдЖрдгрд┐ рдерд╛рдВрдмрддреЗ рддреЗ рдбрдмрдХрдВ. рдбрдмрдХреНрдпрд╛рд╡рд░ рдбрд╛рд╕ рдпреЗрддрд╛рдд рдЖрдгрд┐ рдЭрд▒реНрдпрд╛рд╡рд░ рд░рд╛рдЬрд╣рдВрд╕. рд╡реЗрд│рдкреНрд░рд╕рдВрдЧреА рд╣рд│рд╡реЗрдкрдгрд╛ рдмрд╛рдЬреБрд▓рд╛ рдареЗрд╡реВрди рд╡рд╛рд╕\n",
      "\n",
      "рдЖрдЬрдЪреНрдпрд╛ рдЬрдЧрд╛рдд рд╡рд┐рд╢реБрджреНрдз рдкреНрд░реЗрдо рдХреБрдареЗрдЪ рдорд┐рд│рдд рдирд╛рд╣реА.\n",
      "рд╕рд╡рд╛рдЪреНрдпрд╛ рд╕рд╛рд╡рд░ рдкреНрд░реЗрдо рдХрд░рд╛ рджреЛрдиреНрд╣реАрдВрдЪрд╛ рдлрд╛рдпрджрд╛рдЪ рдЖрд╣реЗ рдкреНрд░реЗрдо рдХрд░рд╛рд▓ рддрд░ рдореА рддреБрдордЪреНрдпрд╛ рд╣реГрджрдпрд╛рдд рдЕрд╕реЗрди рд╡реНрджреЗрд╖ рдХрд░рд╛рд▓ рддрд░ рдореА рддреБрдордЪреНрдпрд╛ рдо\n",
      "\n",
      "рдорд│рд▓реЗрд▓реНрдпрд╛ рд╡рд╛рдЯрд╛ рдЕрдзреЛрдЧрддреАрд▓рд╛ рдХрдзреАрд╣реА рдиреЗрдд рдирд╛рд╣реА, рд╣реЗ рдЬрд┐рддрдХрдВ рдЦрд░рдВ рддрд┐рддрдХреЗрдЪ рддреНрдпрд╛ рдкреНрд░рдЧрддрд┐рдЪрд╛ рдорд╛рд░реНрдЧ рджрд╛рдЦрд╡реАрдд рдирд╛рд╣реА, рд╣реЗ рд╣реА рдЦрд░рдВ.\n",
      "рдХрдерд╛ рд╡рд╕реНрддреВ рдЖрдХрд░реНрд╖рдХ рдЖрд╣реЗ.\n",
      "рдЖрдкрдг рдХрд╛рдирд╛рдВрдиреА рдОрдХрддреЛ рддреЗ рдЦреЛрдЯрдВ \n",
      "\n",
      "рдирд┐рджрд╛рди рдкрд╛рд╕рд╖реНрдЯ рдкреНрд░рддрд┐рд╢рдд рддрд░реА рдЕрд╕рд╛рд╡реЗрдд.\n",
      "рдЖрдгрд┐ рдХрд╖реНрдЯ .\n",
      "рдПрдХрджрд╛ рд╡ рд╕рд░реНрд╡рд╕рд╛рдЧреЛрдиреНрдирддреАрдЪреЗ рд╕рд╣рд╛ рд╕реЛрдкрд╛рди.\n",
      "рдкрд░рд╛рднрд╡рд╛рдЪреА рднреАрддреА рдмрд╛рд│рдЧреВ рдирдХрд╛ рдПрдХ рдореЛрдард╛ рд╡рд┐рдЬрдп рддреБрдордЪреЗ рд╕рд░реНрд╡ рдкрд░рд╛рднрд╡ рдкреБрд╕реВрди рдЯрд╛рдХреВ рд╢рдХрддреЛ.\n",
      "рдЖ\n",
      "\n",
      "рддреНрдпрд╛рдВрдиреА рдорд╛рдЭреЗ рд▓рдЧреНрди рдХрд░рд╛рдпрдЪреЗ рдХреБрдЯреАрд▓ рдХрд╛рд░рд╕реНрдерд╛рди рд░рдЪрд▓реЗ рдЖрд╣реЗ.\n",
      "рдвреАрдЧрднрд░ рдЖрд╢реНрд╡рд╛рд╕рдирд╛рдВрдкреЗрдХреНрд╖рд╛ рдЯреАрдЪрднрд░ рдЬрдЧрд▓рд╛рд╕ рддрд░ рдЬрдЧрд▓рд╛рд╕ .\n",
      "рд╕рдореБрджреНрд░рд╛рдд рдХрд┐рддреА рд▓рд╛рдЯрд╛ рдЖрд╣реЗрдд рд╣реЗ рдорд╣рддреНрд╡рд╛рдЪрд╛ рдирд╕реВрди рддреНрдпрд╛ рдХрд╛рдорд╛рдЪрд╛ рд╡рд┐\n",
      "\n",
      "рдкрд░рд┐рдХреНрд╖рд╛рдЪреНрдпрд╛ рдЙрджреНрджрд┐рд╖реНрдЯрдкреВрд░реНрддреАрдХрдбреЗ рд╣реЛрдгрд╛рд░реА рд╡рд╛рдЯрдЪрд╛рд▓ рдореНрд╣рдгреЗ рддрд░ рддреЗ рдкреБрд╕рд╛рдпрд▓рд╛ рдХрд╛рд░рдг рдЪрд╛рд╣реА рд╡рд╛рд╕рдирд╛ рдордиреБрд╖реНрдпрд╛рдЪрд╛рд░ рднрд┐рдВрдд рд╡рд╛рдврддреЛрдЪ рдЕрд╢реА рд╕реБрдВрджрд░  рджрд┐рд╕рдгреНрдпрд╛рд▓рд╛ рдХрд╛рд╣реАрдЪ рдЕрд░реНрде рдирд╛рд╣реА.\n",
      "рд╡рд┐рдЪрд╛рд░ рд╣реЗрдд\n",
      "\n",
      "рдлрдХреНрдд рд╕реНрд╡рдд:рд╕рд╛рдареА рдЬрдЧрд▓рд╛рд╕ рддрд░ рдореЗрд▓рд╛рд╕ рдЖрдгрд┐ рд╕реНрд╡рддрд╕рд╛рдареА рдЬрдЧреВрди рджреБрд╕рд▒реНрдпрд╛рдВрд╕рд╛рдареА рдЬрдЧрд▓рд╛рд╕ рддрд░ рдЬрдЧрд▓рд╛рд╕ .\n",
      "рддреБрдореНрд╣реА рдХреБрдгрд╛рд▓рд╛рд╣реА рдЖрд╣рд╛рдд рддреНрдпрд╛рдВрдирд╛ рд╡рд╛рд╣рд┐рд▓реЗрд▓реА рдХрд░рд╛рдпрд▓рд╛ рдЬрд╛рдЧреА рд╕рдореБрджреНрд░ рдЧрд╛рдард╛рдпрдЪрд╛ рдЕрд╕реЗрд▓, рдд\n",
      "\n",
      "рдЖрдЬрдЪрд╛ рд╕рдВрдШрд░реНрд╖ рдЙрджреНрдпрд╛рдЪреЗ рд╕рд╛рдорд░реНрдереНрдп рдирд┐рд░реНрдорд╛рдг рдЭрд╛рд▓реЗ рдирд╛рд╣реА .\n",
      "рдЕрд╢рд╛ рд╣реЗ рджреБрдГрдЦрд╛рдЪрдВ рдореЛрд▓ рдЪреБрдХрд╛  рд╕реБрдзрд╛рд░рдгреНрдпрд╛рд╕рд╛рдареА рдЬреЛ  рд╕реНрд╡рддрдГрд╢реАрдЪ рд▓рдврд╛рдИ рдХрд░рддреЛ,  рддреНрдпрд╛рд▓рд╛ рдХреБрдгреАрд╣реА рд╣рд░рд╡реВ рд╢рдХрдд рдирд╛рд╣реА.\n",
      "рдорд╛рдЭреНрдпрд╛ рдЬ\n",
      "\n",
      "рд╣рд╛рддрд╛рдЪреА рдмреЛрдЯреЗ рдЬреНрдпрд╛рдкреНрд░рдорд╛рдгреЗ рд╕рд╛рд░рдЦреА рдирд╕рддрд╛рдд, рддреНрдпрд╛рдЪрдкреНрд░рдорд╛рдгреЗ рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдорд┐рд│рддреЗ.\n",
      "рдЙрддреНрддреЗрдЬрдХ рдкреЗрдпрд╛рдВрдкрд╛рд╕реВрди рдореА рдкрд╣рд┐рд▓реНрдпрд╛ рдкрд╛рд╕реВрдирдЪ рдЕрд▓рд┐рдкреНрдд рдЖрд╣реЗ.\n",
      "рдЖрд╡рдбрддрдВ рддреЗрдЪ рдХрд░реВ рдирдХрд╛, рдЬреЗ рдХрд░рд╛рд╡рдВ рд▓рд╛рдЧрддрдВ рдд\n",
      "\n",
      "рдпрд╛ рдкреБрдвреЗ рдЖрдкрд▓реНрдпрд╛рд▓рд╛ рдореА рдХрд╕рд▓реАрдЪ рддрд╕рджреА рджреЗрдгрд╛рд░ рдирд╛рд╣реА.\n",
      "рдЕрд╡рд┐рдЬрдп рд╣рд╛рдЪ рдЖрдпреБрд╖реНрдпрд╛рддрд▓рд╛ рд╕рд░реНрд╡рд╛рдд рдореЛрдард╛ рд╡рд┐рдЬрдп рдЕрд╕рддреЛ .\n",
      "рд╣реНрд░рджрдпрд╛рдд рдЕрдкрд╛рд░ рдкреНрд░реЗрдо рдЕрд╕рд▓реЗ рдкрд╛рд╣рд┐рдЬреЗ рдЕрд╕ рдирд╛рд╣реА,.\n",
      "рд╣рд╛рддрд╛рдЪреА рдмреЛрдЯреЗ рдЬреНрдпрд╛рдкреНрд░рдорд╛\n",
      "\n",
      "рджреВрдм рдЬреАрд╡рди рдЬрдЧрд╛ рдЖрдгрд┐ рдкреНрд░рддреНрдпреЗрдХ рджрд┐рд╡рд╢реА рдЬреАрд╡рдирд╛рдЪреА рдирд╡реАрди рд╕реБрд░реБрд╡рд╛рдд рдХрд░рд╛ .\n",
      "рдЬреАрд╡рдирд╛рдЪреНрдпрд╛ рд╕рдорд░рд╛рдд рд░рдХреНрддрдмрдВрдмрд╛рд│ рд╡реНрд╣рд╛рдпрдЪреЗ рдкреНрд░рд╕рдВрдЧ рдпрд╛рдпрдЪреЗрдЪ.\n",
      "рдЕрдкрдорд╛рдирд╛рдЪреЗ рдЙрддреНрддрд░ рдПрд╡рдвреЗ рдирдореНрд░рдкрдгреЗ рджреНрдпрд╛ рдХреА ,   рдЕрдк\n",
      "\n",
      "рдХреЛрдгрддреАрд╣реА рдЪрд┐рдВрддрд╛ рдирд╕реВрди рдЕрдиреЗрдХрд╛рдВрдЪреНрдпрд╛ рдЖрдпреБрд╖реНрдпрд╛рд▓рд╛ рд▓рд╛рдЧрд▓реЗрд▓рд╛ рд░реЛрдЧ рдЖрд╣реЗ .\n",
      "рдЖрд╣реНрд▓рд╛рдж рджрд╛рдпрдХ.\n",
      "рдкреНрд░реЗрдо рдорд╛рдгрд╕рд╛рдЪреНрдпрд╛ рд╣рд╛рддреВрди рджрд┐рд▓реНрдпрд╛рд╕ рддреЛ рдХрдореА рдХрдбреВ рд▓рд╛рдЧрддреЛ.\n",
      "рдзреНрд╡реЗрд╖рд╛рд▓рд╛ рдЬреНрдпрд╛рджрд┐рд╡рд╢реА рдЖрдкрд▓рд╛ рд╕рд╛рд╡рд░ рдорд╛\n",
      "\n",
      "рдХрд╛рд░рдг рд╕рд╛рдВрдЧрдгрд╛рд░реА рд▓реЛрдХ рдпрд╢рд╕реНрд╡реА рд╣реЛрдд рдирд╛рд╣реА.\n",
      "рд╡рд┐рдЬреНрдЮрд╛рдирд╛рдЪрдВ рддрдВрддреНрд░ рд╢рд┐рдХрд╛ рдкрдг рдЬрдЧрдгреНрдпрд╛рдЪрд╛ рдордВрддреНрд░ рд╣рд░рд╡реВ рдирдХрд╛.\n",
      "рд╣реЗ рдореА рдЖрдкрд▓реНрдпрд╛рд╡рд░ рд╕реЛрдкрд╡рддреЛ.\n",
      "рдЖрдкрдг рдЬреЗ рдкреЗрд░рддреЛ рддреЗрдЪ рдЙрдЧрд╡рддрдВ .\n",
      "рдЬреНрдпрд╛рд▓рд╛ рдЦрд░реЛрдЦрд░рдЪ рд▓рдХреН\n",
      "\n",
      "рдорд╛рдЭреНрдпрд╛ рдпрд╛ рдореБрдЧреНрдз рд╡рд╛рдХреНрдпрд╛рд▓рд╛ рд╣рд╕рдгреЗ рд╕рд╛рд╣рдЬрд┐рдХ рдЖрд╣реЗ.\n",
      "рд╡рд╛рд╣рддреЛ рддреЛ рдЭрд░рд╛ рдЖрдгрд┐ рдерд╛рдВрдмрддреЗ рддреЗ рдбрдмрдХрдВ. рдбрдмрдХреНрдпрд╛рд╡рд░ рдбрд╛рд╕ рдпреЗрддрд╛рдд рдЖрдгрд┐ рдЭрд▒реНрдпрд╛рд╡рд░ рд░рд╛рдЬрд╣рдВрд╕. рд╡реЗрд│рдк рдЕрд╕рддреЛ.\n",
      "рдкреНрд░рд╛рдЬреНрдЮ рдкрд░реАрдХреНрд╖реЗрдд рдкрд╛рд╕ рдЭрд╛рд▓реЛ\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decode(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "Cell \u001b[0;32mIn[37], line 175\u001b[0m, in \u001b[0;36mBigramLanguageModel.generate\u001b[0;34m(self, idx, max_new_tokens)\u001b[0m\n\u001b[1;32m    173\u001b[0m idx_cond \u001b[38;5;241m=\u001b[39m idx[:, \u001b[38;5;241m-\u001b[39mblock_size:]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# get the predictions\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# focus only on the last time step\u001b[39;00m\n\u001b[1;32m    177\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# becomes (B, C)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[37], line 155\u001b[0m, in \u001b[0;36mBigramLanguageModel.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    153\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m    156\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m    157\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x) \u001b[38;5;66;03m# (B,T,vocab_size)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[37], line 132\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 132\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffwd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlayer_norm(\n\u001b[1;32m    191\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, normalized_shape, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mlayer_norm(\u001b[39minput\u001b[39;49m, normalized_shape, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    print(decode(m.generate(context, max_new_tokens=150)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
